{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2502c061-c5b7-4589-87f0-24ead985a703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from scikit-learn) (1.26.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from matplotlib) (10.2.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Using cached scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "Using cached matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Using cached contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Using cached scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "Using cached threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, pyparsing, kiwisolver, joblib, fonttools, cycler, contourpy, scikit-learn, matplotlib\n",
      "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.49.0 joblib-1.3.2 kiwisolver-1.4.5 matplotlib-3.8.3 pyparsing-3.1.1 scikit-learn-1.4.1.post1 scipy-1.12.0 threadpoolctl-3.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17dae1de-c3a5-4a10-b825-6bbcaff14ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed_value):\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed_value)  # Numpy module.\n",
    "    random.seed(seed_value)  # Python random module.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "set_seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac9483c2-5547-47bf-9457-223d877b4aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  4 08:30:07 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Quadro RTX 5000                Off | 00000000:1C:00.0 Off |                  Off |\n",
      "| 33%   32C    P8               4W / 230W |      6MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b5eac5-4c13-40ac-9f92-306aaadb42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 src/CUB/generate_new_data.py ExtractConcepts --model_path \"ConceptModel__Seed1 old/output/best_model_1.pth\" --data_dir CUB_processed/class_attr_data_10 --out_dir ConceptModel1__PredConcepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f8d55b5-bf09-49b1-a8ec-6d5be2603a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_dirs=['ConceptModel__Seed1 old/output/best_model_1.pth'], model_dirs2=['SequentialModel_WithVal__Seed1/best_model_1.pth'], eval_data='test', use_attr=True, no_img=False, bottleneck=True, image_dir='images', n_class_attr=2, data_dir='CUB_processed/class_attr_data_10', n_attributes=112, attribute_group=None, feature_group_results=True, use_relu=False, use_sigmoid=False, batch_size=16)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Thesis/Code from the arapov server/src/CUB/inference.py\", line 255, in <module>\n",
      "    result = eval(args)\n",
      "  File \"/home/Thesis/Code from the arapov server/src/CUB/inference.py\", line 54, in eval\n",
      "    model2 = torch.load(args.model_dir2)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/serialization.py\", line 986, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/serialization.py\", line 435, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/serialization.py\", line 416, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'SequentialModel_WithVal__Seed1/best_model_1.pth'\n"
     ]
    }
   ],
   "source": [
    "! python3 src/CUB/inference.py -model_dirs \"ConceptModel__Seed1 old/output/best_model_1.pth\" -model_dirs2 SequentialModel_WithVal__Seed1/best_model_1.pth -eval_data test -use_attr -n_attributes 112 -data_dir CUB_processed/class_attr_data_10 -bottleneck -feature_group_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ebb6c6-46d2-4dcb-a0e3-d4914222fbab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='cub', exp='Sequential_CtoY', seed=42, log_dir='SequentialModel_WithVal__Seed1', batch_size=64, epochs=1000, save_step=1000, lr=0.01, weight_decay=4e-05, pretrained=True, freeze=False, use_aux=True, use_attr=True, attr_loss_weight=1.0, no_img=True, bottleneck=False, weighted_loss='', uncertain_labels=False, n_attributes=112, expand_dim=0, n_class_attr=2, data_dir='ConceptModel1__PredConcepts', image_dir='images', resampling=False, end2end=False, optimizer='sgd', ckpt='', scheduler_step=1000, normalize_loss=False, use_relu=False, use_sigmoid=False, connect_CY=False, three_class=False)\n",
      "None\n",
      "Stop epoch:  2000\n",
      "train data path: ConceptModel1__PredConcepts/train.pkl\n",
      "New model best model at epoch 0\n",
      "Epoch [0]:\tTrain loss: 4.0772\tTrain accuracy: 44.1301\tVal loss: 3.0260\tVal acc: 50.7513\tBest val epoch: 0\n",
      "Test accuracy:  tensor([50.3797], device='cuda:0')\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:384: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "Current lr: [0.01]\n",
      "New model best model at epoch 1\n",
      "Epoch [1]:\tTrain loss: 1.5591\tTrain accuracy: 72.8252\tVal loss: 2.5573\tVal acc: 55.5092\tBest val epoch: 1\n",
      "Test accuracy:  tensor([54.8844], device='cuda:0')\n",
      "New model best model at epoch 2\n",
      "Epoch [2]:\tTrain loss: 1.1414\tTrain accuracy: 76.0135\tVal loss: 2.3016\tVal acc: 56.5108\tBest val epoch: 2\n",
      "Test accuracy:  tensor([56.8174], device='cuda:0')\n",
      "New model best model at epoch 3\n",
      "Epoch [3]:\tTrain loss: 1.1316\tTrain accuracy: 77.3438\tVal loss: 2.3546\tVal acc: 58.5142\tBest val epoch: 3\n",
      "Test accuracy:  tensor([57.4560], device='cuda:0')\n",
      "New model best model at epoch 4\n",
      "Epoch [4]:\tTrain loss: 1.0706\tTrain accuracy: 79.0329\tVal loss: 2.2551\tVal acc: 58.9315\tBest val epoch: 4\n",
      "Test accuracy:  tensor([57.2661], device='cuda:0')\n",
      "Epoch [5]:\tTrain loss: 0.9351\tTrain accuracy: 79.7508\tVal loss: 2.3825\tVal acc: 58.1803\tBest val epoch: 4\n",
      "Test accuracy:  tensor([57.8012], device='cuda:0')\n",
      "New model best model at epoch 6\n",
      "Epoch [6]:\tTrain loss: 0.9626\tTrain accuracy: 80.1943\tVal loss: 2.3785\tVal acc: 59.6828\tBest val epoch: 6\n",
      "Test accuracy:  tensor([58.4398], device='cuda:0')\n",
      "Epoch [7]:\tTrain loss: 0.9298\tTrain accuracy: 80.7221\tVal loss: 2.3744\tVal acc: 58.3472\tBest val epoch: 6\n",
      "Test accuracy:  tensor([58.2672], device='cuda:0')\n",
      "Epoch [8]:\tTrain loss: 0.9452\tTrain accuracy: 80.9966\tVal loss: 2.6887\tVal acc: 55.9265\tBest val epoch: 6\n",
      "Test accuracy:  tensor([57.0072], device='cuda:0')\n",
      "New model best model at epoch 9\n",
      "Epoch [9]:\tTrain loss: 0.9107\tTrain accuracy: 80.3843\tVal loss: 2.3640\tVal acc: 60.6845\tBest val epoch: 9\n",
      "Test accuracy:  tensor([58.2672], device='cuda:0')\n",
      "Epoch [10]:\tTrain loss: 0.9103\tTrain accuracy: 81.5034\tVal loss: 2.4273\tVal acc: 59.6828\tBest val epoch: 9\n",
      "Test accuracy:  tensor([59.3200], device='cuda:0')\n",
      "Current lr: [0.01]\n",
      "Epoch [11]:\tTrain loss: 0.7674\tTrain accuracy: 82.6647\tVal loss: 2.4710\tVal acc: 59.9332\tBest val epoch: 9\n",
      "Test accuracy:  tensor([57.2316], device='cuda:0')\n",
      "Epoch [12]:\tTrain loss: 0.8659\tTrain accuracy: 81.8623\tVal loss: 2.4785\tVal acc: 59.5993\tBest val epoch: 9\n",
      "Test accuracy:  tensor([58.7677], device='cuda:0')\n",
      "Epoch [13]:\tTrain loss: 0.7252\tTrain accuracy: 83.5515\tVal loss: 2.4336\tVal acc: 60.0167\tBest val epoch: 9\n",
      "Test accuracy:  tensor([58.8022], device='cuda:0')\n",
      "Epoch [14]:\tTrain loss: 0.8241\tTrain accuracy: 83.3615\tVal loss: 2.5167\tVal acc: 59.9332\tBest val epoch: 9\n",
      "Test accuracy:  tensor([58.7159], device='cuda:0')\n",
      "Epoch [15]:\tTrain loss: 0.8113\tTrain accuracy: 83.8682\tVal loss: 2.5066\tVal acc: 59.6828\tBest val epoch: 9\n",
      "Test accuracy:  tensor([59.2855], device='cuda:0')\n",
      "Epoch [16]:\tTrain loss: 0.8142\tTrain accuracy: 83.6360\tVal loss: 2.5624\tVal acc: 60.2671\tBest val epoch: 9\n",
      "Test accuracy:  tensor([59.9413], device='cuda:0')\n",
      "Epoch [17]:\tTrain loss: 0.8243\tTrain accuracy: 84.2905\tVal loss: 2.6327\tVal acc: 59.0150\tBest val epoch: 9\n",
      "Test accuracy:  tensor([58.6814], device='cuda:0')\n",
      "Epoch [18]:\tTrain loss: 0.7441\tTrain accuracy: 84.3117\tVal loss: 2.5117\tVal acc: 60.2671\tBest val epoch: 9\n",
      "Test accuracy:  tensor([58.9748], device='cuda:0')\n",
      "Epoch [19]:\tTrain loss: 0.7413\tTrain accuracy: 84.6917\tVal loss: 2.5697\tVal acc: 60.5175\tBest val epoch: 9\n",
      "Test accuracy:  tensor([59.7860], device='cuda:0')\n",
      "Epoch [20]:\tTrain loss: 0.6627\tTrain accuracy: 85.0084\tVal loss: 2.5572\tVal acc: 59.9332\tBest val epoch: 9\n",
      "Test accuracy:  tensor([59.9586], device='cuda:0')\n",
      "Current lr: [0.01]\n",
      "Epoch [21]:\tTrain loss: 0.7383\tTrain accuracy: 84.7762\tVal loss: 2.8200\tVal acc: 59.0985\tBest val epoch: 9\n",
      "Test accuracy:  tensor([59.2509], device='cuda:0')\n",
      "Epoch [22]:\tTrain loss: 0.7554\tTrain accuracy: 84.7973\tVal loss: 2.6293\tVal acc: 60.2671\tBest val epoch: 9\n",
      "Test accuracy:  tensor([59.8550], device='cuda:0')\n",
      "Epoch [23]:\tTrain loss: 0.7682\tTrain accuracy: 84.5017\tVal loss: 2.6197\tVal acc: 59.5159\tBest val epoch: 9\n",
      "Test accuracy:  tensor([58.9058], device='cuda:0')\n",
      "Epoch [24]:\tTrain loss: 0.7101\tTrain accuracy: 84.8818\tVal loss: 2.6951\tVal acc: 59.4324\tBest val epoch: 9\n",
      "Test accuracy:  tensor([58.9058], device='cuda:0')\n",
      "New model best model at epoch 25\n",
      "Epoch [25]:\tTrain loss: 0.6630\tTrain accuracy: 85.3041\tVal loss: 2.6376\tVal acc: 61.1853\tBest val epoch: 25\n",
      "Test accuracy:  tensor([60.2347], device='cuda:0')\n",
      "Epoch [26]:\tTrain loss: 0.6755\tTrain accuracy: 86.1909\tVal loss: 2.7239\tVal acc: 58.9315\tBest val epoch: 25\n",
      "Test accuracy:  tensor([58.3017], device='cuda:0')\n",
      "Epoch [27]:\tTrain loss: 0.6685\tTrain accuracy: 86.1487\tVal loss: 2.5844\tVal acc: 61.1853\tBest val epoch: 25\n",
      "Test accuracy:  tensor([59.5616], device='cuda:0')\n",
      "Epoch [28]:\tTrain loss: 0.5945\tTrain accuracy: 86.5498\tVal loss: 2.6371\tVal acc: 60.1836\tBest val epoch: 25\n",
      "Test accuracy:  tensor([60.0449], device='cuda:0')\n",
      "Epoch [29]:\tTrain loss: 0.6741\tTrain accuracy: 85.9375\tVal loss: 2.7230\tVal acc: 60.3506\tBest val epoch: 25\n",
      "Test accuracy:  tensor([59.8205], device='cuda:0')\n",
      "Epoch [30]:\tTrain loss: 0.5772\tTrain accuracy: 86.9299\tVal loss: 2.6346\tVal acc: 60.1836\tBest val epoch: 25\n",
      "Test accuracy:  tensor([59.2164], device='cuda:0')\n",
      "Current lr: [0.01]\n",
      "Epoch [31]:\tTrain loss: 0.5660\tTrain accuracy: 87.0777\tVal loss: 2.7100\tVal acc: 60.6010\tBest val epoch: 25\n",
      "Test accuracy:  tensor([59.5444], device='cuda:0')\n",
      "Epoch [32]:\tTrain loss: 0.5869\tTrain accuracy: 86.9510\tVal loss: 2.7316\tVal acc: 59.6828\tBest val epoch: 25\n",
      "Test accuracy:  tensor([59.3372], device='cuda:0')\n",
      "Epoch [33]:\tTrain loss: 0.6124\tTrain accuracy: 86.9932\tVal loss: 2.8359\tVal acc: 60.1002\tBest val epoch: 25\n",
      "Test accuracy:  tensor([59.0438], device='cuda:0')\n",
      "Epoch [34]:\tTrain loss: 0.6425\tTrain accuracy: 86.7399\tVal loss: 2.7396\tVal acc: 60.0167\tBest val epoch: 25\n",
      "Test accuracy:  tensor([59.3200], device='cuda:0')\n",
      "Epoch [35]:\tTrain loss: 0.5732\tTrain accuracy: 87.3944\tVal loss: 2.6824\tVal acc: 59.9332\tBest val epoch: 25\n",
      "Test accuracy:  tensor([59.2855], device='cuda:0')\n",
      "Epoch [36]:\tTrain loss: 0.5025\tTrain accuracy: 87.9856\tVal loss: 2.6116\tVal acc: 60.3506\tBest val epoch: 25\n",
      "Test accuracy:  tensor([59.3718], device='cuda:0')\n",
      "Epoch [37]:\tTrain loss: 0.5381\tTrain accuracy: 88.0701\tVal loss: 2.8557\tVal acc: 61.1018\tBest val epoch: 25\n",
      "Test accuracy:  tensor([59.0956], device='cuda:0')\n",
      "New model best model at epoch 38\n",
      "Epoch [38]:\tTrain loss: 0.5825\tTrain accuracy: 87.6267\tVal loss: 2.8721\tVal acc: 61.5192\tBest val epoch: 38\n",
      "Test accuracy:  tensor([59.0956], device='cuda:0')\n",
      "Epoch [39]:\tTrain loss: 0.6255\tTrain accuracy: 87.8167\tVal loss: 2.6723\tVal acc: 60.5175\tBest val epoch: 38\n",
      "Test accuracy:  tensor([59.9758], device='cuda:0')\n",
      "Epoch [40]:\tTrain loss: 0.6059\tTrain accuracy: 87.8801\tVal loss: 2.7173\tVal acc: 60.5175\tBest val epoch: 38\n",
      "Test accuracy:  tensor([59.7342], device='cuda:0')\n",
      "Current lr: [0.01]\n",
      "Epoch [41]:\tTrain loss: 0.5331\tTrain accuracy: 88.2812\tVal loss: 2.7209\tVal acc: 59.3489\tBest val epoch: 38\n",
      "Test accuracy:  tensor([59.5271], device='cuda:0')\n",
      "Epoch [42]:\tTrain loss: 0.5011\tTrain accuracy: 88.0912\tVal loss: 2.7346\tVal acc: 60.1002\tBest val epoch: 38\n",
      "Test accuracy:  tensor([59.8895], device='cuda:0')\n",
      "Epoch [43]:\tTrain loss: 0.6006\tTrain accuracy: 87.4789\tVal loss: 2.7355\tVal acc: 60.9349\tBest val epoch: 38\n",
      "Test accuracy:  tensor([59.4063], device='cuda:0')\n",
      "Epoch [44]:\tTrain loss: 0.5085\tTrain accuracy: 88.4291\tVal loss: 2.6999\tVal acc: 60.1002\tBest val epoch: 38\n",
      "Test accuracy:  tensor([59.4235], device='cuda:0')\n",
      "Epoch [45]:\tTrain loss: 0.5067\tTrain accuracy: 88.6402\tVal loss: 2.8324\tVal acc: 59.5993\tBest val epoch: 38\n",
      "Test accuracy:  tensor([59.4063], device='cuda:0')\n",
      "Epoch [46]:\tTrain loss: 0.5536\tTrain accuracy: 88.1968\tVal loss: 2.7394\tVal acc: 60.8514\tBest val epoch: 38\n",
      "Test accuracy:  tensor([59.6997], device='cuda:0')\n",
      "Epoch [47]:\tTrain loss: 0.4658\tTrain accuracy: 88.9780\tVal loss: 2.8634\tVal acc: 59.7663\tBest val epoch: 38\n",
      "Test accuracy:  tensor([59.6824], device='cuda:0')\n",
      "New model best model at epoch 48\n",
      "Epoch [48]:\tTrain loss: 0.5236\tTrain accuracy: 88.7036\tVal loss: 2.6869\tVal acc: 61.6861\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.6479], device='cuda:0')\n",
      "Epoch [49]:\tTrain loss: 0.5095\tTrain accuracy: 88.6824\tVal loss: 2.9387\tVal acc: 61.2688\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.2337], device='cuda:0')\n",
      "Epoch [50]:\tTrain loss: 0.5359\tTrain accuracy: 88.2390\tVal loss: 2.7647\tVal acc: 59.1820\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.2509], device='cuda:0')\n",
      "Current lr: [0.01]\n",
      "Epoch [51]:\tTrain loss: 0.5255\tTrain accuracy: 88.5769\tVal loss: 2.7729\tVal acc: 60.9349\tBest val epoch: 48\n",
      "Test accuracy:  tensor([60.2175], device='cuda:0')\n",
      "Epoch [52]:\tTrain loss: 0.4853\tTrain accuracy: 89.0836\tVal loss: 2.8331\tVal acc: 60.0167\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.6997], device='cuda:0')\n",
      "Epoch [53]:\tTrain loss: 0.4880\tTrain accuracy: 89.3792\tVal loss: 2.8579\tVal acc: 60.1836\tBest val epoch: 48\n",
      "Test accuracy:  tensor([60.3383], device='cuda:0')\n",
      "Epoch [54]:\tTrain loss: 0.5453\tTrain accuracy: 89.1047\tVal loss: 2.7869\tVal acc: 60.4341\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.8205], device='cuda:0')\n",
      "Epoch [55]:\tTrain loss: 0.5234\tTrain accuracy: 89.0625\tVal loss: 2.8644\tVal acc: 59.8497\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.5444], device='cuda:0')\n",
      "Epoch [56]:\tTrain loss: 0.5164\tTrain accuracy: 89.0836\tVal loss: 2.8373\tVal acc: 59.8497\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.2164], device='cuda:0')\n",
      "Epoch [57]:\tTrain loss: 0.4291\tTrain accuracy: 90.5617\tVal loss: 2.9066\tVal acc: 59.5993\tBest val epoch: 48\n",
      "Test accuracy:  tensor([58.5606], device='cuda:0')\n",
      "Epoch [58]:\tTrain loss: 0.4870\tTrain accuracy: 89.5270\tVal loss: 2.9390\tVal acc: 60.8514\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.7860], device='cuda:0')\n",
      "Epoch [59]:\tTrain loss: 0.4782\tTrain accuracy: 89.7804\tVal loss: 2.9690\tVal acc: 60.4341\tBest val epoch: 48\n",
      "Test accuracy:  tensor([58.9575], device='cuda:0')\n",
      "Epoch [60]:\tTrain loss: 0.5265\tTrain accuracy: 89.6115\tVal loss: 2.8685\tVal acc: 60.1002\tBest val epoch: 48\n",
      "Test accuracy:  tensor([60.3383], device='cuda:0')\n",
      "Current lr: [0.01]\n",
      "Epoch [61]:\tTrain loss: 0.4476\tTrain accuracy: 89.8649\tVal loss: 2.9673\tVal acc: 60.4341\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.3200], device='cuda:0')\n",
      "Epoch [62]:\tTrain loss: 0.5200\tTrain accuracy: 89.7171\tVal loss: 2.9255\tVal acc: 59.8497\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.1129], device='cuda:0')\n",
      "Epoch [63]:\tTrain loss: 0.4509\tTrain accuracy: 90.0127\tVal loss: 2.8517\tVal acc: 60.7679\tBest val epoch: 48\n",
      "Test accuracy:  tensor([60.1484], device='cuda:0')\n",
      "Epoch [64]:\tTrain loss: 0.4850\tTrain accuracy: 89.9916\tVal loss: 2.9185\tVal acc: 60.4341\tBest val epoch: 48\n",
      "Test accuracy:  tensor([60.1829], device='cuda:0')\n",
      "Epoch [65]:\tTrain loss: 0.3873\tTrain accuracy: 90.8362\tVal loss: 2.8724\tVal acc: 60.1836\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.2682], device='cuda:0')\n",
      "Epoch [66]:\tTrain loss: 0.4231\tTrain accuracy: 90.7095\tVal loss: 2.9689\tVal acc: 60.6845\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.1992], device='cuda:0')\n",
      "Epoch [67]:\tTrain loss: 0.4811\tTrain accuracy: 89.6959\tVal loss: 2.9675\tVal acc: 60.9349\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.2337], device='cuda:0')\n",
      "Epoch [68]:\tTrain loss: 0.4710\tTrain accuracy: 89.1258\tVal loss: 3.2234\tVal acc: 59.6828\tBest val epoch: 48\n",
      "Test accuracy:  tensor([58.8367], device='cuda:0')\n",
      "Epoch [69]:\tTrain loss: 0.4643\tTrain accuracy: 90.7728\tVal loss: 2.9940\tVal acc: 60.2671\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.4235], device='cuda:0')\n",
      "Epoch [70]:\tTrain loss: 0.4607\tTrain accuracy: 90.8362\tVal loss: 3.0430\tVal acc: 61.2688\tBest val epoch: 48\n",
      "Test accuracy:  tensor([60.0276], device='cuda:0')\n",
      "Current lr: [0.01]\n",
      "Epoch [71]:\tTrain loss: 0.4603\tTrain accuracy: 90.4983\tVal loss: 2.8926\tVal acc: 60.5175\tBest val epoch: 48\n",
      "Test accuracy:  tensor([60.1312], device='cuda:0')\n",
      "Epoch [72]:\tTrain loss: 0.4673\tTrain accuracy: 90.3505\tVal loss: 2.8414\tVal acc: 61.3523\tBest val epoch: 48\n",
      "Test accuracy:  tensor([60.1657], device='cuda:0')\n",
      "Epoch [73]:\tTrain loss: 0.4075\tTrain accuracy: 90.7306\tVal loss: 2.9210\tVal acc: 61.3523\tBest val epoch: 48\n",
      "Test accuracy:  tensor([60.1312], device='cuda:0')\n",
      "Epoch [74]:\tTrain loss: 0.3611\tTrain accuracy: 91.7652\tVal loss: 2.8679\tVal acc: 59.6828\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.8550], device='cuda:0')\n",
      "Epoch [75]:\tTrain loss: 0.4493\tTrain accuracy: 90.5405\tVal loss: 2.8842\tVal acc: 61.4357\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.9413], device='cuda:0')\n",
      "Epoch [76]:\tTrain loss: 0.4465\tTrain accuracy: 90.8150\tVal loss: 3.0180\tVal acc: 60.3506\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.8378], device='cuda:0')\n",
      "Epoch [77]:\tTrain loss: 0.4972\tTrain accuracy: 90.4350\tVal loss: 3.0855\tVal acc: 60.7679\tBest val epoch: 48\n",
      "Test accuracy:  tensor([59.9586], device='cuda:0')\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Thesis/Code from the arapov server/src/experiments.py\", line 101, in <module>\n",
      "    run_experiments(dataset, args)\n",
      "  File \"/home/Thesis/Code from the arapov server/src/experiments.py\", line 44, in run_experiments\n",
      "    train_Chat_to_y_and_test_on_Chat(*args)\n",
      "  File \"/home/Thesis/Code from the arapov server/src/CUB/train.py\", line 268, in train_Chat_to_y_and_test_on_Chat\n",
      "    train(model, args)\n",
      "  File \"/home/Thesis/Code from the arapov server/src/CUB/train.py\", line 200, in train\n",
      "    train_loss_meter, train_acc_meter = run_epoch_simple(model, optimizer, train_loader, train_loss_meter, train_acc_meter, criterion, args, is_training=True)\n",
      "  File \"/home/Thesis/Code from the arapov server/src/CUB/train.py\", line 29, in run_epoch_simple\n",
      "    for _, data in enumerate(loader):\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/Thesis/Code from the arapov server/src/CUB/dataset.py\", line 55, in __getitem__\n",
      "    img = Image.open(img_path).convert('RGB')\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/PIL/Image.py\", line 922, in convert\n",
      "    self.load()\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/PIL/ImageFile.py\", line 291, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 src/experiments.py cub Sequential_CtoY --seed 42 -log_dir SequentialModel_WithVal__Seed1 -e 1000 -optimizer sgd -pretrained -use_aux -use_attr -data_dir ConceptModel1__PredConcepts -n_attributes 112 -no_img -b 64 -weight_decay 0.00004 -lr 0.01 -scheduler_step 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1516f105-137b-4fb2-946d-6fb438af7040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_dirs=['ConceptModel__Seed1 old/output/best_model_1.pth'], model_dirs2=['SequentialModel_WithVal__Seed1/best_model_42.pth'], eval_data='test', use_attr=True, no_img=False, bottleneck=True, image_dir='images', n_class_attr=2, data_dir='CUB_processed/class_attr_data_10', n_attributes=112, attribute_group=None, feature_group_results=True, use_relu=False, use_sigmoid=False, batch_size=16)\n",
      "Average top 1 class accuracy: 72.00552\n",
      "Average top 3 class accuracy: 85.48499\n",
      "Average top 5 class accuracy: 89.88609\n",
      "Average attribute accuracy: 96.05457\n",
      "Accuracy bins:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 112, 0]\n",
      "F1 bins:\n",
      "[0, 0, 0, 0, 0, 0, 0, 4, 51, 57, 0]\n",
      "Total 1's predicted: 0.20080810197741505\n",
      "Avg attribute balanced acc: 0.93570\n",
      "Avg attribute F1 score: 0.90277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98    515913\n",
      "           1       0.91      0.89      0.90    133015\n",
      "\n",
      "    accuracy                           0.96    648928\n",
      "   macro avg       0.94      0.94      0.94    648928\n",
      "weighted avg       0.96      0.96      0.96    648928\n",
      "\n",
      "\n",
      "Error of y: 0.2799 +- 0.0000, Error of C: 0.0395 +- 0.0000\n"
     ]
    }
   ],
   "source": [
    "! python3 src/CUB/inference.py -model_dirs \"ConceptModel__Seed1 old/output/best_model_1.pth\" -model_dirs2 SequentialModel_WithVal__Seed1/best_model_42.pth -eval_data test -use_attr -n_attributes 112 -data_dir CUB_processed/class_attr_data_10 -bottleneck -feature_group_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd2aa872-9040-4743-801d-81cbbec8420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Sequential(nn.Module):\n",
    "    def __init__(self, model1_path, model2_path):\n",
    "        super(Sequential, self).__init__()\n",
    "        self.model1 = torch.load(model1_path)\n",
    "        self.model2 = torch.load(model2_path)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model1(x)\n",
    "        x = torch.stack(x).squeeze().t()\n",
    "        x = self.model2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a613bde5-a69e-42ff-9c42-ee63c1fb9239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Thesis/Code from the arapov server\n"
     ]
    }
   ],
   "source": [
    "# from Experiment1.models import *\n",
    "import os\n",
    "\n",
    "os.chdir('../')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc2d444-a997-4918-a463-bc320a768181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model_1_path = r'ConceptModel__Seed1 old/output/best_model_1.pth'\n",
    "model_2_path = r'SequentialModel_WithVal__Seed1/best_model_42.pth'\n",
    "model = Sequential(model_1_path, model_2_path).to(device)\n",
    "model.eval()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e108e04-89c6-40a1-bcaf-65542b2550fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CUB.dataset import load_data\n",
    "# def load_data(pkl_paths, use_attr, no_img, batch_size, uncertain_label=False, n_class_attr=2, image_dir='images', resampling=False, resol=299):\n",
    "n_concepts = 112\n",
    "batch_size = 16\n",
    "test_loader = load_data(['CUB_processed/class_attr_data_10/test.pkl'], True, False, 32)\n",
    "train_loader = load_data(['CUB_processed/class_attr_data_10/train.pkl'], True, False, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f3bbfda-acd9-454c-b200-ec161c370105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over the whole test set: 0.7201\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "for image, class_label, attributes in test_loader:\n",
    "    image, class_label = image.to(device), class_label.to(device)\n",
    "    output = model(image)\n",
    "    pred = output.argmax(dim=1)\n",
    "    total_correct += (class_label.int() == pred.int()).sum().item()\n",
    "    total_samples += class_label.size(0)\n",
    "\n",
    "accuracy = total_correct / total_samples\n",
    "print(f'Accuracy over the whole test set: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bd14640-b53a-4db6-9a43-44074c4705dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attacker:\n",
    "    def __init__(self, batch_size, model_name) -> None:\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.example = torch.zeros((batch_size, 3, 299, 299), requires_grad=True).to(self.device)\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def pgd_linf_targ(self, model, data_loader, epsilon, alpha, num_iter, y_targ):\n",
    "        \"\"\"\n",
    "        Training on the whole test set\n",
    "        \"\"\"\n",
    "        delta = torch.zeros_like(self.example, requires_grad=True)\n",
    "        for t in range(num_iter):\n",
    "            print(f\"Running iteration {t}\")\n",
    "            for X, y, concepts in data_loader:\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                if self.model_name == 'joint' or self.model_name == 'standard':\n",
    "                    yp = model(X + delta[:X.shape[0]])[0]\n",
    "                else:\n",
    "                    yp = model(X + delta[:X.shape[0]])\n",
    "                loss = 2*yp[:, y_targ].sum() - yp.sum()\n",
    "                loss.backward()\n",
    "\n",
    "                delta = delta + alpha * delta.grad.detach().sign()\n",
    "                delta = delta.clamp(-epsilon, epsilon).detach().requires_grad_(True)\n",
    "\n",
    "                # Clear gradients after updating delta\n",
    "                if delta.grad is not None:\n",
    "                    delta.grad.zero_()\n",
    "        return delta.detach()\n",
    "    \n",
    "    def test_addv(self, model, test_loader, delta):\n",
    "        model.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for image, class_label, attributes in test_loader:\n",
    "            image, class_label = image.to(device), class_label.to(device)\n",
    "            if self.model_name == 'joint' or self.model_name == 'standard':\n",
    "                output = model(image + delta[:image.shape[0]])[0]\n",
    "            else:\n",
    "                output = model(image + delta[:image.shape[0]])\n",
    "            pred = output.argmax(dim=1)\n",
    "            total_correct += (class_label.int() == pred.int()).sum().item()\n",
    "            total_samples += class_label.size(0)\n",
    "        \n",
    "        accuracy = total_correct / total_samples\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1508efbd-3809-4c03-b62c-1278455a4ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iteration 0\n",
      "Running iteration 1\n",
      "Running iteration 2\n",
      "Running iteration 3\n",
      "Running iteration 4\n",
      "Running iteration 5\n",
      "Running iteration 6\n",
      "Running iteration 7\n",
      "Running iteration 8\n",
      "Running iteration 9\n"
     ]
    }
   ],
   "source": [
    "attacker = Attacker(32, 'sequential')\n",
    "config = dict(\n",
    "    n_epochs = 10,\n",
    "    epsilon = 0.05,\n",
    "    alpha = 1e-2,\n",
    "    num_iter = 10,\n",
    "    y_targ = 2,\n",
    ")\n",
    "delta_sequential = attacker.pgd_linf_targ(model, train_loader, config[\"epsilon\"], config[\"alpha\"], config[\"num_iter\"], config[\"y_targ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18f0df21-66db-48ed-9ec7-0607bca8b7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10769761822575077"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delta_sequential = torch.load('Delta/Sequential model/delta_sequential.pt').to('cuda')\n",
    "attacker.test_addv(model, test_loader, delta_sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb489d87-face-4b78-b84a-86844e5e4f69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0500,  0.0300,  0.0500,  ..., -0.0400, -0.0400, -0.0100],\n",
       "          [ 0.0500, -0.0500,  0.0500,  ..., -0.0300, -0.0300, -0.0100],\n",
       "          [ 0.0500, -0.0500,  0.0500,  ..., -0.0300, -0.0400,  0.0000],\n",
       "          ...,\n",
       "          [-0.0500, -0.0500, -0.0500,  ..., -0.0100,  0.0400,  0.0400],\n",
       "          [ 0.0100, -0.0100, -0.0300,  ..., -0.0500,  0.0000,  0.0400],\n",
       "          [ 0.0100, -0.0500, -0.0100,  ...,  0.0000,  0.0400,  0.0400]],\n",
       "\n",
       "         [[-0.0500, -0.0500, -0.0500,  ...,  0.0100, -0.0100,  0.0100],\n",
       "          [-0.0500, -0.0500, -0.0400,  ...,  0.0000,  0.0100, -0.0300],\n",
       "          [-0.0500, -0.0500, -0.0500,  ...,  0.0000,  0.0100, -0.0300],\n",
       "          ...,\n",
       "          [ 0.0100, -0.0500, -0.0500,  ..., -0.0400,  0.0200,  0.0500],\n",
       "          [-0.0100, -0.0300, -0.0300,  ..., -0.0500, -0.0400, -0.0200],\n",
       "          [ 0.0400,  0.0000,  0.0200,  ..., -0.0500, -0.0400, -0.0400]],\n",
       "\n",
       "         [[ 0.0500, -0.0500,  0.0400,  ...,  0.0100,  0.0300, -0.0200],\n",
       "          [ 0.0500, -0.0500,  0.0400,  ..., -0.0500, -0.0300,  0.0000],\n",
       "          [ 0.0500, -0.0500,  0.0500,  ..., -0.0500, -0.0100, -0.0300],\n",
       "          ...,\n",
       "          [ 0.0300,  0.0300, -0.0200,  ..., -0.0500,  0.0200,  0.0400],\n",
       "          [ 0.0500, -0.0500, -0.0500,  ..., -0.0300,  0.0300, -0.0200],\n",
       "          [ 0.0500, -0.0400,  0.0300,  ..., -0.0200, -0.0300, -0.0100]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0200, -0.0400,  0.0400,  ..., -0.0300,  0.0100,  0.0100],\n",
       "          [ 0.0200,  0.0300,  0.0400,  ...,  0.0100,  0.0100,  0.0100],\n",
       "          [-0.0100, -0.0400,  0.0100,  ...,  0.0500, -0.0300,  0.0200],\n",
       "          ...,\n",
       "          [ 0.0500,  0.0500,  0.0400,  ...,  0.0000, -0.0500,  0.0200],\n",
       "          [ 0.0000, -0.0200,  0.0200,  ...,  0.0500,  0.0400,  0.0300],\n",
       "          [-0.0100,  0.0000,  0.0000,  ...,  0.0500,  0.0300,  0.0400]],\n",
       "\n",
       "         [[ 0.0100, -0.0100,  0.0300,  ..., -0.0200,  0.0000, -0.0300],\n",
       "          [-0.0300,  0.0100,  0.0200,  ...,  0.0100, -0.0300, -0.0500],\n",
       "          [-0.0300, -0.0300,  0.0100,  ..., -0.0500, -0.0300, -0.0500],\n",
       "          ...,\n",
       "          [-0.0200,  0.0400,  0.0400,  ..., -0.0400, -0.0400, -0.0500],\n",
       "          [-0.0300,  0.0000,  0.0100,  ..., -0.0500, -0.0500, -0.0500],\n",
       "          [ 0.0100, -0.0200,  0.0400,  ..., -0.0400, -0.0500, -0.0500]],\n",
       "\n",
       "         [[ 0.0300,  0.0300, -0.0300,  ...,  0.0000, -0.0100, -0.0200],\n",
       "          [ 0.0300,  0.0300,  0.0300,  ..., -0.0100, -0.0300, -0.0400],\n",
       "          [ 0.0300,  0.0400, -0.0200,  ..., -0.0400, -0.0400, -0.0500],\n",
       "          ...,\n",
       "          [-0.0200,  0.0400,  0.0200,  ...,  0.0500,  0.0500,  0.0500],\n",
       "          [-0.0400, -0.0200,  0.0400,  ...,  0.0500,  0.0500,  0.0500],\n",
       "          [ 0.0000,  0.0000,  0.0300,  ...,  0.0500,  0.0500,  0.0500]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0500,  0.0500,  0.0500,  ..., -0.0300,  0.0400,  0.0300],\n",
       "          [ 0.0500,  0.0500,  0.0500,  ..., -0.0400, -0.0400,  0.0300],\n",
       "          [ 0.0500,  0.0200,  0.0500,  ..., -0.0400, -0.0300, -0.0200],\n",
       "          ...,\n",
       "          [ 0.0300,  0.0400,  0.0400,  ...,  0.0300,  0.0100, -0.0100],\n",
       "          [ 0.0300,  0.0200,  0.0400,  ...,  0.0100,  0.0000,  0.0300],\n",
       "          [ 0.0100,  0.0200,  0.0400,  ...,  0.0100,  0.0200,  0.0200]],\n",
       "\n",
       "         [[-0.0200, -0.0200, -0.0400,  ..., -0.0300, -0.0300, -0.0300],\n",
       "          [ 0.0200, -0.0500,  0.0200,  ..., -0.0400, -0.0300, -0.0500],\n",
       "          [ 0.0200, -0.0100,  0.0400,  ..., -0.0500, -0.0400, -0.0300],\n",
       "          ...,\n",
       "          [ 0.0400,  0.0400,  0.0400,  ..., -0.0200, -0.0300, -0.0300],\n",
       "          [ 0.0400,  0.0400,  0.0400,  ..., -0.0200, -0.0100, -0.0300],\n",
       "          [-0.0500,  0.0000, -0.0300,  ...,  0.0100, -0.0300,  0.0000]],\n",
       "\n",
       "         [[-0.0400, -0.0500, -0.0200,  ...,  0.0400,  0.0400, -0.0100],\n",
       "          [-0.0500, -0.0500,  0.0000,  ..., -0.0300,  0.0400,  0.0400],\n",
       "          [-0.0500, -0.0500, -0.0500,  ...,  0.0000,  0.0000,  0.0300],\n",
       "          ...,\n",
       "          [-0.0400,  0.0300,  0.0400,  ..., -0.0300, -0.0100,  0.0000],\n",
       "          [-0.0200,  0.0400,  0.0500,  ..., -0.0200,  0.0200,  0.0200],\n",
       "          [-0.0400,  0.0400,  0.0200,  ..., -0.0200,  0.0200,  0.0300]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.0200,  0.0200,  0.0400,  ..., -0.0300, -0.0400,  0.0000],\n",
       "          [ 0.0200, -0.0300,  0.0100,  ...,  0.0200, -0.0400,  0.0000],\n",
       "          [ 0.0200, -0.0500,  0.0300,  ..., -0.0400, -0.0400, -0.0400],\n",
       "          ...,\n",
       "          [ 0.0200, -0.0500, -0.0200,  ...,  0.0500,  0.0500,  0.0200],\n",
       "          [-0.0100,  0.0200, -0.0200,  ..., -0.0100,  0.0300, -0.0100],\n",
       "          [ 0.0300,  0.0300,  0.0400,  ...,  0.0100,  0.0400,  0.0100]],\n",
       "\n",
       "         [[-0.0500, -0.0500, -0.0500,  ..., -0.0300, -0.0300, -0.0300],\n",
       "          [-0.0500, -0.0500, -0.0500,  ...,  0.0100, -0.0100,  0.0200],\n",
       "          [-0.0500, -0.0500, -0.0200,  ..., -0.0100, -0.0200,  0.0200],\n",
       "          ...,\n",
       "          [-0.0100,  0.0000, -0.0200,  ...,  0.0200, -0.0300, -0.0500],\n",
       "          [-0.0100,  0.0000, -0.0200,  ..., -0.0100, -0.0500, -0.0200],\n",
       "          [-0.0200,  0.0000, -0.0400,  ..., -0.0200, -0.0200, -0.0100]],\n",
       "\n",
       "         [[ 0.0500,  0.0500,  0.0000,  ...,  0.0000, -0.0200, -0.0300],\n",
       "          [ 0.0500,  0.0000, -0.0300,  ...,  0.0100,  0.0000, -0.0500],\n",
       "          [ 0.0400,  0.0400,  0.0500,  ..., -0.0400,  0.0500,  0.0400],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0300,  0.0300,  ..., -0.0100,  0.0400,  0.0100],\n",
       "          [ 0.0000,  0.0300,  0.0400,  ...,  0.0400,  0.0100,  0.0000],\n",
       "          [ 0.0000,  0.0100,  0.0100,  ...,  0.0100,  0.0200,  0.0200]]],\n",
       "\n",
       "\n",
       "        [[[-0.0300, -0.0200, -0.0500,  ..., -0.0400, -0.0200,  0.0500],\n",
       "          [ 0.0500, -0.0500,  0.0500,  ..., -0.0400, -0.0500,  0.0500],\n",
       "          [ 0.0500, -0.0400,  0.0500,  ...,  0.0300, -0.0500, -0.0500],\n",
       "          ...,\n",
       "          [-0.0300,  0.0100, -0.0300,  ...,  0.0300,  0.0200,  0.0100],\n",
       "          [-0.0500, -0.0100,  0.0000,  ...,  0.0000, -0.0300,  0.0500],\n",
       "          [ 0.0100, -0.0500,  0.0100,  ...,  0.0200,  0.0500,  0.0500]],\n",
       "\n",
       "         [[ 0.0500,  0.0500,  0.0500,  ..., -0.0500, -0.0500, -0.0500],\n",
       "          [ 0.0500, -0.0300,  0.0500,  ..., -0.0500, -0.0500, -0.0500],\n",
       "          [-0.0100, -0.0500,  0.0500,  ..., -0.0500, -0.0500, -0.0500],\n",
       "          ...,\n",
       "          [-0.0100,  0.0000,  0.0200,  ..., -0.0200, -0.0100, -0.0500],\n",
       "          [-0.0100,  0.0000,  0.0200,  ..., -0.0500, -0.0500, -0.0500],\n",
       "          [ 0.0300,  0.0200,  0.0500,  ...,  0.0200,  0.0200,  0.0000]],\n",
       "\n",
       "         [[-0.0500, -0.0500, -0.0500,  ...,  0.0500,  0.0500,  0.0500],\n",
       "          [-0.0500, -0.0500, -0.0500,  ...,  0.0400,  0.0500,  0.0500],\n",
       "          [-0.0500, -0.0500, -0.0500,  ...,  0.0400,  0.0500,  0.0500],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0500, -0.0200,  ..., -0.0300,  0.0200, -0.0400],\n",
       "          [ 0.0000,  0.0300, -0.0300,  ..., -0.0400, -0.0300, -0.0300],\n",
       "          [ 0.0000,  0.0400, -0.0200,  ..., -0.0300, -0.0100, -0.0300]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0400,  0.0300,  0.0400,  ..., -0.0400,  0.0500,  0.0500],\n",
       "          [ 0.0400, -0.0500,  0.0400,  ...,  0.0400,  0.0300,  0.0300],\n",
       "          [ 0.0500, -0.0500,  0.0500,  ...,  0.0500,  0.0300, -0.0200],\n",
       "          ...,\n",
       "          [-0.0200, -0.0400, -0.0400,  ..., -0.0500, -0.0100,  0.0100],\n",
       "          [-0.0200, -0.0400, -0.0400,  ...,  0.0200,  0.0000, -0.0200],\n",
       "          [ 0.0100, -0.0400, -0.0500,  ..., -0.0100,  0.0200,  0.0000]],\n",
       "\n",
       "         [[-0.0300, -0.0500, -0.0500,  ..., -0.0500, -0.0300, -0.0300],\n",
       "          [-0.0400, -0.0500, -0.0400,  ..., -0.0500, -0.0300, -0.0300],\n",
       "          [-0.0500, -0.0500,  0.0400,  ..., -0.0400, -0.0300, -0.0300],\n",
       "          ...,\n",
       "          [-0.0300, -0.0400, -0.0400,  ..., -0.0500, -0.0500, -0.0400],\n",
       "          [-0.0200, -0.0400, -0.0400,  ..., -0.0400, -0.0500, -0.0500],\n",
       "          [ 0.0400, -0.0400, -0.0400,  ..., -0.0100,  0.0100, -0.0300]],\n",
       "\n",
       "         [[ 0.0400, -0.0500, -0.0300,  ..., -0.0500, -0.0200, -0.0500],\n",
       "          [ 0.0500, -0.0500, -0.0300,  ...,  0.0500, -0.0400, -0.0500],\n",
       "          [-0.0200, -0.0500,  0.0200,  ...,  0.0500, -0.0500, -0.0400],\n",
       "          ...,\n",
       "          [ 0.0400,  0.0000,  0.0000,  ...,  0.0500,  0.0500,  0.0500],\n",
       "          [ 0.0300, -0.0300,  0.0100,  ...,  0.0500,  0.0500,  0.0500],\n",
       "          [ 0.0400, -0.0100,  0.0400,  ...,  0.0500,  0.0500,  0.0500]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To demonstrate saving and loading a tensor, we'll use PyTorch as it's a common framework for such operations.\n",
    "import torch\n",
    "\n",
    "\n",
    "# Saving the tensor to a file\n",
    "torch.save(delta_sequential.cpu(), 'Delta/Sequential model/delta_sequential.pt')\n",
    "\n",
    "# Loading the tensor back\n",
    "loaded_tensor = torch.load('Delta/Sequential model/delta_sequential.pt')\n",
    "\n",
    "# Display the loaded tensor\n",
    "loaded_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e58fed-7066-426e-b560-cdabec82321e",
   "metadata": {},
   "source": [
    "# Testing the Joint model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a80c6b00-439e-4df6-9e1e-ab6b2611d430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "joint_model_path = 'Joint0.01Model__Seed1/outputs/best_model_1.pth'\n",
    "joint_model = torch.load(joint_model_path)\n",
    "joint_model.eval()\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "604a48aa-d671-4665-9757-c334a89e7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"\n",
    "    Computes the precision@k for the specified values of k\n",
    "    output and target are Torch tensors\n",
    "    \"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    temp = target.view(1, -1).expand_as(pred)\n",
    "    temp = temp.cuda()\n",
    "    correct = pred.eq(temp)\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        # print(correct[:k].t().shape)\n",
    "        correct_k = correct[:k].t().reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cccf068-2bc4-46b3-9d9a-1cd51923ec7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over the whole test set: 0.7584\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "for image, class_label, attributes in test_loader:\n",
    "    image, class_label = image.to(device), class_label.to(device)\n",
    "    output = joint_model(image)\n",
    "    # print(len(output[1]))\n",
    "    # print(output[0][0].shape)\n",
    "    # print(output[1][0].shape)\n",
    "    # break\n",
    "    class_outputs = output[0]\n",
    "    # _, preds = class_outputs.topk(1, 1, True, True)\n",
    "    pred = class_outputs.argmax(dim=1)\n",
    "    total_correct += (class_label.int() == pred.int()).sum().item()\n",
    "    total_samples += class_label.size(0)\n",
    "\n",
    "accur = total_correct / total_samples\n",
    "print(f'Accuracy over the whole test set: {accur:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06d599b1-2311-4be8-817c-163fc62b26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker = Attacker(64, model_name='joint')\n",
    "config = dict(\n",
    "    n_epochs = 10,\n",
    "    epsilon = 0.05,\n",
    "    alpha = 1e-2,\n",
    "    num_iter = 10,\n",
    "    y_targ = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ac90e21-8e02-40bc-949f-9332bc9c5750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iteration 0\n",
      "Running iteration 1\n",
      "Running iteration 2\n",
      "Running iteration 3\n",
      "Running iteration 4\n",
      "Running iteration 5\n",
      "Running iteration 6\n",
      "Running iteration 7\n",
      "Running iteration 8\n",
      "Running iteration 9\n"
     ]
    }
   ],
   "source": [
    "delta_joint = attacker.pgd_linf_targ(joint_model, train_loader, config[\"epsilon\"], config[\"alpha\"], config[\"num_iter\"], config[\"y_targ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e417abc3-71e9-4185-9bce-55944f759148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2317915084570245"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacker.test_addv(joint_model, test_loader, delta_joint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be493f-1b6f-415d-8e5b-ea49ac754807",
   "metadata": {},
   "source": [
    "# Adversarial training the joint model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954da7b1-cee3-44bc-abd4-33ce9ede815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class AdversarialTrainer:\n",
    "    def __init__(self, model_name):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def epoch_adversarial(self, loader, model, attack, opt=None, **kwargs):\n",
    "        \"\"\"Adversarial training/evaluation epoch over the dataset\"\"\"\n",
    "        total_loss, total_err = 0.,0.\n",
    "        for X,y,_ in loader:\n",
    "            X,y = X.to(self.device), y.to(self.device)\n",
    "            delta = attack(model, X, y)\n",
    "            if self.model_name == 'joint' or self.model_name == 'standard':\n",
    "                yp = model(X + delta[:X.shape[0]])[0]\n",
    "            else:\n",
    "                yp = model(X + delta[:X.shape[0]])\n",
    "            loss = nn.CrossEntropyLoss()(yp,y)\n",
    "            if opt:\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            total_err += (yp.max(dim=1)[1] != y.argmax(dim=1)).sum().item()\n",
    "            total_loss += loss.item() * X.shape[0]\n",
    "        return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
    "    \n",
    "    def pgd_linf_targ(self, model, X,y, epsilon=0.05, alpha=1e-2, num_iter=10, y_targ=2):\n",
    "        \"\"\"\n",
    "        Training on the whole test set\n",
    "        \"\"\"\n",
    "        X, y = X.to(self.device), y.to(self.device)\n",
    "        delta = torch.zeros_like(X, requires_grad=True)\n",
    "        for t in range(num_iter):\n",
    "            if self.model_name == 'joint' or self.model_name == 'standard':\n",
    "                yp = model(X + delta[:X.shape[0]])[0]\n",
    "            else:\n",
    "                yp = model(X + delta[:X.shape[0]])\n",
    "            loss = 2*yp[:, y_targ].sum() - yp.sum()\n",
    "            loss.backward()\n",
    "\n",
    "            delta = delta + alpha * delta.grad.detach().sign()\n",
    "            delta = delta.clamp(-epsilon, epsilon).detach().requires_grad_(True)\n",
    "\n",
    "            # Clear gradients after updating delta\n",
    "            if delta.grad is not None:\n",
    "                delta.grad.zero_()\n",
    "        return delta.detach()\n",
    "    \n",
    "\n",
    "    def train_model(self, model, num_iter, train_loader, test_loader):\n",
    "        opt = optim.Adam(model.parameters(), lr=1e-4)\n",
    "        for t in range(num_iter):\n",
    "            print(f\"Running iteration {t}\")\n",
    "            train_err, train_loss = self.epoch_adversarial(train_loader, model, self.pgd_linf_targ, opt)\n",
    "            adv_err, adv_loss = self.epoch_adversarial(test_loader, model, self.pgd_linf_targ)\n",
    "            if t == 4:\n",
    "                for param_group in opt.param_groups:\n",
    "                    param_group[\"lr\"] = 1e-5\n",
    "            print(*(\"{:.6f}\".format(i) for i in (train_err, adv_err)), sep=\"\\t\")\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde51a8d-fd0c-4d24-908d-293d941d2840",
   "metadata": {},
   "source": [
    "# Standard model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8e1f22d2-523a-4e27-9ec9-da44477c165f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "End2EndModel(\n",
       "  (first_model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (all_fc): ModuleList(\n",
       "        (0-111): 112 x FC(\n",
       "          (fc): Linear(in_features=768, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (all_fc): ModuleList(\n",
       "      (0-111): 112 x FC(\n",
       "        (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (sec_model): MLP(\n",
       "    (linear): Linear(in_features=112, out_features=200, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "standard_model = torch.load(\"Standard0Model_Seed1/outputs/best_model_1.pth\")\n",
    "standard_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b429a08b-4812-4ae9-84df-27bc823df96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over the whole test set: 0.7760\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "for image, class_label, attributes in test_loader:\n",
    "    image, class_label = image.to(device), class_label.to(device)\n",
    "    output = standard_model(image)\n",
    "    # print(len(output[1]))\n",
    "    # print(output[0][0].shape)\n",
    "    # print(output[1][0].shape)\n",
    "    # break\n",
    "    class_outputs = output[0]\n",
    "    # print(class_outputs)\n",
    "    # _, preds = class_outputs.topk(1, 1, True, True)\n",
    "    pred = class_outputs.argmax(dim=1)\n",
    "    total_correct += (class_label.int() == pred.int()).sum().item()\n",
    "    total_samples += class_label.size(0)\n",
    "\n",
    "accur = total_correct / total_samples\n",
    "print(f'Accuracy over the whole test set: {accur:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d3033241-25e1-4e0b-86d1-13db730a0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker = Attacker(64, model_name='standard')\n",
    "config = dict(\n",
    "    n_epochs = 10,\n",
    "    epsilon = 0.05,\n",
    "    alpha = 1e-2,\n",
    "    num_iter = 10,\n",
    "    y_targ = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "52445306-a456-4255-aacc-01a6c27d12db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iteration 0\n",
      "Running iteration 1\n",
      "Running iteration 2\n",
      "Running iteration 3\n",
      "Running iteration 4\n",
      "Running iteration 5\n",
      "Running iteration 6\n",
      "Running iteration 7\n",
      "Running iteration 8\n",
      "Running iteration 9\n"
     ]
    }
   ],
   "source": [
    "delta_standard = attacker.pgd_linf_targ(standard_model, train_loader, config[\"epsilon\"], config[\"alpha\"], config[\"num_iter\"], config[\"y_targ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b1684625-ad0e-4afe-a9aa-783edfb3c476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038833275802554364"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacker.test_addv(standard_model, test_loader, delta_standard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
