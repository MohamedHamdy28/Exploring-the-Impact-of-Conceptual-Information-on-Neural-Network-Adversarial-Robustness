{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing the seeds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed_value):\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed_value)  # Numpy module.\n",
    "    random.seed(seed_value)  # Python random module.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mohammad/mohamed-thesis\n"
     ]
    }
   ],
   "source": [
    "# from Experiment1.models import *\n",
    "import os\n",
    "\n",
    "os.chdir('../')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CUB.dataset import load_data\n",
    "# def load_data(pkl_paths, use_attr, no_img, batch_size, uncertain_label=False, n_class_attr=2, image_dir='images', resampling=False, resol=299):\n",
    "n_concepts = 112\n",
    "batch_size = 16\n",
    "test_loader = load_data(['CUB_processed/class_attr_data_10/test.pkl'], True, False, 32)\n",
    "train_loader = load_data(['CUB_processed/class_attr_data_10/train.pkl'], True, False, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Sequential(nn.Module):\n",
    "    def __init__(self, model1_path, model2_path):\n",
    "        super(Sequential, self).__init__()\n",
    "        self.model1 = torch.load(model1_path)\n",
    "        self.model2 = torch.load(model2_path)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # try:\n",
    "        #     x = self.model1(x)\n",
    "        #     x = torch.stack(x).squeeze().t()\n",
    "        #     x = self.model2(x)\n",
    "        # except:\n",
    "        #     x = torch.stack(x[0]).squeeze().t()\n",
    "        #     x = self.model2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.model1(x)\n",
    "        # print(x.shape)\n",
    "        x = torch.stack(x).squeeze().t()\n",
    "        # print(x)\n",
    "        x = self.model2(x)\n",
    "        # print(x.shape)\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Joint(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "        super(Joint, self).__init__()\n",
    "        self.model = torch.load(model_path)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)[0]\n",
    "        if isinstance(x, list):\n",
    "            x = x[0]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Standard(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "        super(Standard, self).__init__()\n",
    "        self.model = torch.load(model_path)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)[0]\n",
    "        if isinstance(x, list):\n",
    "            x = x[0]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "model_1_path = r'ConceptModel__Seed1 old/output/best_model_1.pth'\n",
    "model_2_path = r'SequentialModel_WithVal__Seed1/best_model_42.pth'\n",
    "sequential = Sequential(model_1_path, model_2_path).to(device)\n",
    "sequential.eval()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "joint_model_path = 'Joint0.01Model__Seed1/outputs/best_model_1.pth'\n",
    "joint_model = Joint(joint_model_path).to(device)\n",
    "joint_model.eval()\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "standard_model = Standard(\"Standard0Model_Seed1/outputs/best_model_1.pth\").to(device)\n",
    "standard_model.eval()\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacking the models with other attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Sequential_0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [22:05<00:00,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 43.61%\n",
      "0.4361408353469106\n",
      "Loaded Sequential_001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [22:57<00:00,  7.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 37.09%\n",
      "0.3709009319986193\n",
      "Loaded Sequential_0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [24:14<00:00,  7.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 24.59%\n",
      "0.24594408008284432\n",
      "Loaded Sequential_005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [23:40<00:00,  7.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 13.77%\n",
      "0.1377286848463928\n",
      "Loaded joint_model_0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [21:04<00:00,  6.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 38.45%\n",
      "0.38453572661373836\n",
      "Loaded joint_model_001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [21:22<00:00,  7.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 32.26%\n",
      "0.3225750776665516\n",
      "Loaded joint_model_0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [23:30<00:00,  7.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 25.18%\n",
      "0.25181221953745253\n",
      "Loaded joint_model_005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [23:04<00:00,  7.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 15.59%\n",
      "0.1558508802209182\n",
      "Loaded standard_model_0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [21:32<00:00,  7.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 48.27%\n",
      "0.4827407663099758\n",
      "Loaded standard_model_001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [22:16<00:00,  7.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 43.46%\n",
      "0.4345875043148084\n",
      "Loaded standard_model_0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [23:40<00:00,  7.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 35.28%\n",
      "0.35277873662409387\n",
      "Loaded standard_model_005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [24:33<00:00,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 24.66%\n",
      "0.2466344494304453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def deepfool_attack(model, test_loader, eps):\n",
    "    bounds = (-0.25, 0.25)\n",
    "    fmodel = fb.PyTorchModel(model, bounds=bounds)\n",
    "    # Set the attack method\n",
    "    attack = fb.attacks.LinfDeepFoolAttack()\n",
    "\n",
    "    # Track the number of correct predictions.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Wrap the test_loader with tqdm for a progress bar\n",
    "    for images, labels, _ in tqdm(test_loader, desc=\"Attacking Images\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Run the attack\n",
    "        raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=eps)\n",
    "        \n",
    "        # Predict the labels for the adversarial images\n",
    "        logits = model(clipped_advs)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        # Update the number of correct predictions.\n",
    "        correct += torch.sum(preds == labels).item()\n",
    "        total += len(labels)\n",
    "\n",
    "    # Calculate the final accuracy for the adversarial images.\n",
    "    final_accuracy = correct / total\n",
    "    print(f\"Accuracy on adversarial examples: {final_accuracy*100:.2f}%\")\n",
    "    return final_accuracy\n",
    "\n",
    "models = ['Sequential', 'joint_model', 'standard_model']\n",
    "models_classes = {'Sequential': Sequential, 'joint_model': Joint, 'standard_model': Standard}\n",
    "save_models_path = r\"src/Adversarially trained models\"\n",
    "csv_file_path = r\"src/Adversarially trained models/experiments.csv\"\n",
    "attack_config = {\n",
    "    'eps_step': 0.01,\n",
    "    'max_iter': 10,\n",
    "    'clip_values': (-0.25, 0.25),\n",
    "    'input_shape': (3, 299, 299),\n",
    "    'nb_classes': 200\n",
    "}\n",
    "\n",
    "\n",
    "eps_values = [0.0005, 0.001, 0.0025, 0.005]\n",
    "experiments = []\n",
    "# Loading the models\n",
    "for model_name in models:\n",
    "  for eps in eps_values:\n",
    "    experiment = {\n",
    "        'model_name': model_name,\n",
    "        'Trained on eps': eps\n",
    "    }\n",
    "    if model_name == 'Sequential':\n",
    "        model_1_path = r'ConceptModel__Seed1 old/output/best_model_1.pth'\n",
    "        model_2_path = r'SequentialModel_WithVal__Seed1/best_model_42.pth'\n",
    "        model = Sequential(model_1_path, model_2_path).to(device)\n",
    "        model.eval()\n",
    "    elif model_name == 'joint_model':\n",
    "        joint_model_path = 'Joint0.01Model__Seed1/outputs/best_model_1.pth'\n",
    "        model = Joint(joint_model_path).to(device)\n",
    "        model.eval()\n",
    "    elif model_name == 'standard_model':\n",
    "        model = Standard(\"Standard0Model_Seed1/outputs/best_model_1.pth\").to(device)\n",
    "        \n",
    "    model_path = f\"{save_models_path}/{model_name}_{str(eps).split('.')[1]}.pth\"\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(f\"Loaded {model_name}_{str(eps).split('.')[1]}\")\n",
    "    # selected_attack = attack_mapping['CWL2']\n",
    "    model.eval()\n",
    "    # accuracy = attack_deepfool(model, test_loader,test_labels, attack_config)\n",
    "    accuracy = deepfool_attack(model, test_loader, eps)\n",
    "    print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Sequential_0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [31:14<00:00, 10.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 58.51%\n",
      "0.5850880220918191\n",
      "Loaded Sequential_001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [35:05<00:00, 11.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 55.13%\n",
      "0.5512599240593717\n",
      "Loaded Sequential_0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [39:59<00:00, 13.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 49.59%\n",
      "0.4958577839143942\n",
      "Loaded Sequential_005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [40:31<00:00, 13.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 43.04%\n",
      "0.43044528822920264\n",
      "Loaded joint_model_0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [31:26<00:00, 10.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 51.05%\n",
      "0.5105281325509148\n",
      "Loaded joint_model_001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [35:58<00:00, 11.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 48.69%\n",
      "0.48688298239558164\n",
      "Loaded joint_model_0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [42:41<00:00, 14.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 48.74%\n",
      "0.48740075940628236\n",
      "Loaded joint_model_005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [44:03<00:00, 14.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 44.63%\n",
      "0.44632378322402483\n",
      "Loaded standard_model_0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [31:13<00:00, 10.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 61.74%\n",
      "0.6173627890921644\n",
      "Loaded standard_model_001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [36:25<00:00, 12.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 62.15%\n",
      "0.6215050051777701\n",
      "Loaded standard_model_0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images:  54%|█████▍    | 98/182 [25:28<23:03, 16.47s/it]"
     ]
    }
   ],
   "source": [
    "import foolbox as fb\n",
    "from tqdm import tqdm\n",
    "\n",
    "def cw_l2_attack(model, test_loader, eps):\n",
    "    bounds = (-0.25, 0.25)\n",
    "    fmodel = fb.PyTorchModel(model, bounds=bounds)\n",
    "    # Set the attack method\n",
    "    attack = fb.attacks.L2CarliniWagnerAttack(steps=10, confidence=0)\n",
    "\n",
    "    # Track the number of correct predictions.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Wrap the test_loader with tqdm for a progress bar\n",
    "    for images, labels, _ in tqdm(test_loader, desc=\"Attacking Images\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Run the attack\n",
    "        raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=eps)\n",
    "        \n",
    "        # Predict the labels for the adversarial images\n",
    "        logits = model(clipped_advs)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        # Update the number of correct predictions.\n",
    "        correct += torch.sum(preds == labels).item()\n",
    "        total += len(labels)\n",
    "\n",
    "    # Calculate the final accuracy for the adversarial images.\n",
    "    final_accuracy = correct / total\n",
    "    print(f\"Accuracy on adversarial examples: {final_accuracy*100:.2f}%\")\n",
    "    return final_accuracy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "models = ['Sequential', 'joint_model', 'standard_model']\n",
    "models_classes = {'Sequential': Sequential, 'joint_model': Joint, 'standard_model': Standard}\n",
    "save_models_path = r\"src/Adversarially trained models\"\n",
    "csv_file_path = r\"src/Adversarially trained models/experiments.csv\"\n",
    "attack_config = {\n",
    "    'eps_step': 0.01,\n",
    "    'max_iter': 10,\n",
    "    'clip_values': (-0.25, 0.25),\n",
    "    'input_shape': (3, 299, 299),\n",
    "    'nb_classes': 200\n",
    "}\n",
    "# # Example usage:\n",
    "# attack_mapping = {\n",
    "#     'CWL2': CarliniL2Method,\n",
    "#     'CWLinf': CarliniLInfMethod,\n",
    "#     'DeepFool': DeepFool\n",
    "# }\n",
    "\n",
    "eps_values = [0.0005, 0.001, 0.0025, 0.005]\n",
    "experiments = []\n",
    "# Loading the models\n",
    "for model_name in models:\n",
    "  for eps in eps_values:\n",
    "    experiment = {\n",
    "        'model_name': model_name,\n",
    "        'Trained on eps': eps\n",
    "    }\n",
    "    if model_name == 'Sequential':\n",
    "        model_1_path = r'ConceptModel__Seed1 old/output/best_model_1.pth'\n",
    "        model_2_path = r'SequentialModel_WithVal__Seed1/best_model_42.pth'\n",
    "        model = Sequential(model_1_path, model_2_path).to(device)\n",
    "        model.eval()\n",
    "    elif model_name == 'joint_model':\n",
    "        joint_model_path = 'Joint0.01Model__Seed1/outputs/best_model_1.pth'\n",
    "        model = Joint(joint_model_path).to(device)\n",
    "        model.eval()\n",
    "    elif model_name == 'standard_model':\n",
    "        model = Standard(\"Standard0Model_Seed1/outputs/best_model_1.pth\").to(device)\n",
    "        \n",
    "    model_path = f\"{save_models_path}/{model_name}_{str(eps).split('.')[1]}.pth\"\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(f\"Loaded {model_name}_{str(eps).split('.')[1]}\")\n",
    "    # selected_attack = attack_mapping['CWL2']\n",
    "    model.eval()\n",
    "    # accuracy = attack_deepfool(model, test_loader,test_labels, attack_config)\n",
    "    accuracy = cw_l2_attack(model, test_loader, eps)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded standard_model_0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [44:46<00:00, 14.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 61.65%\n",
      "0.6164998274076631\n",
      "Loaded standard_model_005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking Images: 100%|██████████| 182/182 [47:14<00:00, 15.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 58.73%\n",
      "0.5873317224715222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import foolbox as fb\n",
    "from tqdm import tqdm\n",
    "\n",
    "def cw_l2_attack(model, test_loader, eps):\n",
    "    bounds = (-0.25, 0.25)\n",
    "    fmodel = fb.PyTorchModel(model, bounds=bounds)\n",
    "    # Set the attack method\n",
    "    attack = fb.attacks.L2CarliniWagnerAttack(steps=10, confidence=0)\n",
    "\n",
    "    # Track the number of correct predictions.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Wrap the test_loader with tqdm for a progress bar\n",
    "    for images, labels, _ in tqdm(test_loader, desc=\"Attacking Images\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Run the attack\n",
    "        raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=eps)\n",
    "        \n",
    "        # Predict the labels for the adversarial images\n",
    "        logits = model(clipped_advs)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        # Update the number of correct predictions.\n",
    "        correct += torch.sum(preds == labels).item()\n",
    "        total += len(labels)\n",
    "\n",
    "    # Calculate the final accuracy for the adversarial images.\n",
    "    final_accuracy = correct / total\n",
    "    print(f\"Accuracy on adversarial examples: {final_accuracy*100:.2f}%\")\n",
    "    return final_accuracy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "models = ['Sequential', 'joint_model', 'standard_model']\n",
    "models_classes = {'Sequential': Sequential, 'joint_model': Joint, 'standard_model': Standard}\n",
    "save_models_path = r\"src/Adversarially trained models\"\n",
    "csv_file_path = r\"src/Adversarially trained models/experiments.csv\"\n",
    "attack_config = {\n",
    "    'eps_step': 0.01,\n",
    "    'max_iter': 10,\n",
    "    'clip_values': (-0.25, 0.25),\n",
    "    'input_shape': (3, 299, 299),\n",
    "    'nb_classes': 200\n",
    "}\n",
    "# # Example usage:\n",
    "# attack_mapping = {\n",
    "#     'CWL2': CarliniL2Method,\n",
    "#     'CWLinf': CarliniLInfMethod,\n",
    "#     'DeepFool': DeepFool\n",
    "# }\n",
    "\n",
    "eps_values = [0.0005, 0.001, 0.0025, 0.005]\n",
    "experiments = []\n",
    "# Loading the models\n",
    "for model_name in models:\n",
    "  if model_name != 'standard_model':\n",
    "     continue\n",
    "  for eps in eps_values[2:]:\n",
    "    experiment = {\n",
    "        'model_name': model_name,\n",
    "        'Trained on eps': eps\n",
    "    }\n",
    "    if model_name == 'Sequential':\n",
    "        model_1_path = r'ConceptModel__Seed1 old/output/best_model_1.pth'\n",
    "        model_2_path = r'SequentialModel_WithVal__Seed1/best_model_42.pth'\n",
    "        model = Sequential(model_1_path, model_2_path).to(device)\n",
    "        model.eval()\n",
    "    elif model_name == 'joint_model':\n",
    "        joint_model_path = 'Joint0.01Model__Seed1/outputs/best_model_1.pth'\n",
    "        model = Joint(joint_model_path).to(device)\n",
    "        model.eval()\n",
    "    elif model_name == 'standard_model':\n",
    "        model = Standard(\"Standard0Model_Seed1/outputs/best_model_1.pth\").to(device)\n",
    "        \n",
    "    model_path = f\"{save_models_path}/{model_name}_{str(eps).split('.')[1]}.pth\"\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(f\"Loaded {model_name}_{str(eps).split('.')[1]}\")\n",
    "    # selected_attack = attack_mapping['CWL2']\n",
    "    model.eval()\n",
    "    # accuracy = attack_deepfool(model, test_loader,test_labels, attack_config)\n",
    "    accuracy = cw_l2_attack(model, test_loader, eps)\n",
    "    print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
