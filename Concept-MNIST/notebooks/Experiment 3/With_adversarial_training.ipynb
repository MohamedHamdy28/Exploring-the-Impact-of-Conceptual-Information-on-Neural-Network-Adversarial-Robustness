{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "w3C3L_zbKN7h"
      },
      "outputs": [],
      "source": [
        "from mimetypes import init\n",
        "from pyexpat import model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "from torchvision import transforms\n",
        "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pdb\n",
        "import argparse\n",
        "from torch import optim\n",
        "\n",
        "class MNISTDatasetWithConcepts(Dataset):\n",
        "\tdef __init__(self,split,num_classes,transform):\n",
        "\t\tisTrain = False\n",
        "\t\tif split == \"train\":\n",
        "\t\t\tisTrain=True\n",
        "\t\tself.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\t\tself.data = MNIST(root = \"./synthetic_datasets\",train=isTrain, download=True)\n",
        "\t\tself.num_classes = num_classes\n",
        "\t\tself.transform = transform\n",
        "\t\t# print(len(set([self.data[i][1] for i in range(len(self.data))])))\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.data)\n",
        "\n",
        "\tdef __getitem__(self,idx):\n",
        "\t\timg,label = self.data[idx][0],self.data[idx][1]\n",
        "\t\tonehot = torch.zeros((self.num_classes,))\n",
        "\t\tonehot[label] =1\n",
        "\t\tconcept = self.make_concepts_mnist(label)\n",
        "\t\tlabel = onehot.to(self.device)\n",
        "\t\treturn [self.transform(img).to(self.device),label,concept]\n",
        "\n",
        "\tdef make_concepts_mnist(self,label):\n",
        "\t\tif label == 0:\n",
        "\t\t\thard_label = torch.tensor([1,0,0,0,0,0,0,0,0,0]+[1,0,0,1,0,0,0,0])\n",
        "\t\telif label == 1:\n",
        "\t\t\thard_label = torch.tensor([0,1,0,0,0,0,0,0,0,0]+[0,1,0,0,1,1,0,1])\n",
        "\t\telif label == 2:\n",
        "\t\t\thard_label = torch.tensor([0,0,1,0,0,0,0,0,0,0]+[1,1,0,0,1,0,0,1])\n",
        "\t\telif label == 3:\n",
        "\t\t\thard_label = torch.tensor([0,0,0,1,0,0,0,0,0,0]+[1,0,0,0,0,0,0,0])\n",
        "\t\telif label == 4:\n",
        "\t\t\thard_label = torch.tensor([0,0,0,0,1,0,0,0,0,0]+[0,1,1,0,1,1,1,0])\n",
        "\t\telif label == 5:\n",
        "\t\t\thard_label = torch.tensor([0,0,0,0,0,1,0,0,0,0]+[1,1,0,0,1,1,1,0])\n",
        "\t\telif label == 6:\n",
        "\t\t\thard_label = torch.tensor([0,0,0,0,0,0,1,0,0,0]+[1,0,1,1,0,0,0,1])\n",
        "\t\telif label == 7:\n",
        "\t\t\thard_label = torch.tensor([0,0,0,0,0,0,0,1,0,0]+[0,1,0,0,1,0,1,0])\n",
        "\t\telif label == 8:\n",
        "\t\t\thard_label = torch.tensor([0,0,0,0,0,0,0,0,1,0]+[1,0,1,1,0,0,1,1])\n",
        "\t\telif label == 9:\n",
        "\t\t\thard_label = torch.tensor([0,0,0,0,0,0,0,0,0,1]+[1,0,1,1,0,0,1,0])\n",
        "\n",
        "\t\t# pdb.set_trace()\n",
        "\n",
        "\t\t# hard_label = torch.zeros((self.num_classes,))\n",
        "\t\t# hard_label[label] = 1\n",
        "\t\thard_label = hard_label.float().to(self.device)\n",
        "\t\treturn hard_label\n",
        "\n",
        "\n",
        "def load_mnist_dataloader(split,bsz):\n",
        "\tdataset = MNISTDatasetWithConcepts(split = split, num_classes = 10, transform=ToTensor())\n",
        "\tdataloader = DataLoader(dataset, batch_size=bsz, shuffle=True)\n",
        "\treturn dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = load_mnist_dataloader(split = \"train\",bsz=64)\n",
        "test_loader = load_mnist_dataloader(split = \"test\",bsz=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeObSYkbRXju",
        "outputId": "49da8f1c-066f-44ae-998a-6ec459a83b05"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./synthetic_datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 149444329.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./synthetic_datasets/MNIST/raw/train-images-idx3-ubyte.gz to ./synthetic_datasets/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./synthetic_datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 38419186.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./synthetic_datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ./synthetic_datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./synthetic_datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 47889673.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./synthetic_datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ./synthetic_datasets/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./synthetic_datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7153784.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./synthetic_datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./synthetic_datasets/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "hPTT4KSoRaCZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class g(nn.Module):\n",
        "    \"\"\"The network g consists of 2 convolutional\n",
        "    layers with 32 channels each, along with a maxpool\n",
        "    layer in between followed by a fully connected\n",
        "    layer.\"\"\"\n",
        "\n",
        "    def __init__(self, n_concepts):\n",
        "        super(g, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
        "        self.fc1 = nn.Linear(800, 128)\n",
        "        self.fc2 = nn.Linear(128, 10+n_concepts*2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        non_overlapping, overlapping = x[:,:10], x[:,10:]\n",
        "        return non_overlapping, overlapping\n",
        "\n",
        "class f(nn.Module):\n",
        "    def __init__(self, input_size) -> None:\n",
        "        super(f, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def split_concepts(concepts):\n",
        "    return concepts[:,:10], concepts[:,10:]\n",
        "\n",
        "class Sequential(nn.Module):\n",
        "    def __init__(self, n_concepts):\n",
        "        super(Sequential, self).__init__()\n",
        "        self.g_model = g(n_concepts).to(device)\n",
        "        self.f_model = f(10+n_concepts*2).to(device)\n",
        "\n",
        "        # Defining the training parameters for the concepts model g\n",
        "        self.g_optimizer = torch.optim.Adam(self.g_model.parameters(), lr=1e-4)\n",
        "        self.g_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Defining the training parameters for the prediction model f\n",
        "        self.learned_g = False\n",
        "        self.f_optimizer = torch.optim.Adam(self.f_model.parameters(), lr=1e-4)\n",
        "        self.f_criterion = nn.CrossEntropyLoss()\n",
        "        self.name = 'sequential'\n",
        "\n",
        "    def split_concepts(self, concepts):\n",
        "        return concepts[:,:10], concepts[:,10:]\n",
        "\n",
        "    def loss_overlapping(self, overlapping, y_true):\n",
        "        total_loss = 0\n",
        "        for i in range(0, overlapping.shape[1], 2):\n",
        "            loss = self.g_criterion(overlapping[:, i:i+2], y_true[:, int(i/2)].long())\n",
        "            total_loss += loss\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "    def train_g(self, train_loader, epochs):\n",
        "        self.g_model.train()\n",
        "        for epoch in range(epochs):\n",
        "            for images, labels, concepts in train_loader:\n",
        "                images, labels, concepts = images.to(device), labels.to(device), concepts.to(device)\n",
        "                y_true_non_overlapping, y_true_overlapping = self.split_concepts(concepts)\n",
        "\n",
        "                self.g_optimizer.zero_grad()\n",
        "                non_overlapping, overlapping = self.g_model(images)\n",
        "\n",
        "                # Calculate the loss for non_overlaaping concepts\n",
        "                loss_non_overlapping = self.g_criterion(non_overlapping, y_true_non_overlapping.argmax(dim=1))\n",
        "\n",
        "                # Calculate the loss for overlapping concepts\n",
        "                loss_overlapping = self.loss_overlapping(overlapping, y_true_overlapping)\n",
        "\n",
        "                # Calculate the total loss\n",
        "                loss = loss_non_overlapping + loss_overlapping\n",
        "                loss.backward()\n",
        "                self.g_optimizer.step()\n",
        "            print(f\"Epoch: {epoch+1}, Loss: {loss.item():.3f}\")\n",
        "        self.learned_g = True\n",
        "\n",
        "    def calc_acc_non_overlapping(self, test_loader):\n",
        "        self.g_model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, _, concepts in test_loader:\n",
        "                images, concepts = images.to(device), concepts.to(device)\n",
        "                y_true_non_overlapping, _ = self.split_concepts(concepts)\n",
        "                non_overlapping, _ = self.g_model(images)\n",
        "                y_pred_non_overlapping = non_overlapping.argmax(dim=1)\n",
        "                correct += (y_pred_non_overlapping == y_true_non_overlapping.argmax(dim=1)).sum().item()\n",
        "                total += y_true_non_overlapping.size(0)\n",
        "\n",
        "        return correct / total if total > 0 else 0\n",
        "\n",
        "    def calc_acc_overlapping(self, test_loader):\n",
        "        self.g_model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, _, concepts in test_loader:\n",
        "                images, concepts = images.to(device), concepts.to(device)\n",
        "                _, y_true_overlapping = self.split_concepts(concepts)\n",
        "                _, overlapping = self.g_model(images)\n",
        "\n",
        "                for i in range(0, overlapping.shape[1], 2):\n",
        "                    y_pred_overlapping = overlapping[:, i:i+2].argmax(dim=1)\n",
        "                    correct += (y_pred_overlapping == y_true_overlapping[:, int(i/2)]).sum().item()\n",
        "                    total += y_true_overlapping.size(0)\n",
        "\n",
        "        return correct / total if total > 0 else 0\n",
        "\n",
        "    def calc_acc_g(self, test_loader):\n",
        "        self.g_model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, _, concepts in test_loader:\n",
        "                images, concepts = images.to(device), concepts.to(device)\n",
        "                y_true_non_overlapping, y_true_overlapping = self.split_concepts(concepts)\n",
        "                non_overlapping, overlapping = self.g_model(images)\n",
        "\n",
        "                y_pred_non_overlapping = non_overlapping.argmax(dim=1)\n",
        "                correct += (y_pred_non_overlapping == y_true_non_overlapping.argmax(dim=1)).sum().item()\n",
        "                total += y_true_non_overlapping.size(0)\n",
        "\n",
        "                for i in range(0, overlapping.shape[1], 2):\n",
        "                    y_pred_overlapping = overlapping[:, i:i+2].argmax(dim=1)\n",
        "                    correct += (y_pred_overlapping == y_true_overlapping[:, int(i/2)]).sum().item()\n",
        "                    total += y_true_overlapping.size(0)\n",
        "\n",
        "        return correct / total if total > 0 else 0\n",
        "\n",
        "    def train_f(self, train_loader, epochs):\n",
        "        if not self.learned_g:\n",
        "            raise \"You have to train g before training f in sequential training\"\n",
        "        self.f_model.train()\n",
        "        for epoch in range(epochs):\n",
        "            for images, labels, _ in train_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                self.f_optimizer.zero_grad()\n",
        "\n",
        "                non_overlapping, overlapping = self.g_model(images)\n",
        "                # Concatenate the concepts\n",
        "                overlapping_concat = torch.cat([non_overlapping, overlapping], dim=1)\n",
        "                y_pred = self.f_model(overlapping_concat)\n",
        "                loss = self.f_criterion(y_pred, labels.argmax(dim=1))\n",
        "                loss.backward()\n",
        "                self.f_optimizer.step()\n",
        "            print(f\"Epoch: {epoch+1}, Loss: {loss.item():.3f}\")\n",
        "\n",
        "    def calc_acc_prediction(self, test_loader, delta=None):\n",
        "        accuracies = []\n",
        "        for images, labels, _ in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            if delta is not None:\n",
        "                y_pred = self.forward(images + delta[:images.shape[0]]).argmax(dim=1)\n",
        "            else:\n",
        "                y_pred = self.forward(images).argmax(dim=1)\n",
        "            acc = (y_pred == labels.argmax(dim=1)).float().mean().item()\n",
        "            accuracies.append(acc)\n",
        "        return sum(accuracies)/len(accuracies)\n",
        "\n",
        "    def train(self, train_loader, epochs=20):\n",
        "        self.train_g(train_loader, epochs)\n",
        "        self.train_f(train_loader, epochs)\n",
        "    def forward(self, x):\n",
        "        non_overlapping, overlapping = self.g_model(x)\n",
        "        # Concatenate the concepts\n",
        "        overlapping = torch.cat([non_overlapping, overlapping], dim=1)\n",
        "        return self.f_model(overlapping)\n",
        "\n",
        "    def save_g(self):\n",
        "        torch.save(self.g_model.state_dict(), \"g_model1.pth\")\n",
        "\n",
        "    def load_g(self, path):\n",
        "        self.g_model.load_state_dict(torch.load(path))\n",
        "        self.learned_g = True\n",
        "\n",
        "    def save_f(self):\n",
        "        torch.save(self.f_model.state_dict(), \"f_model1.pth\")\n",
        "\n",
        "    def load_f(self, path):\n",
        "        self.f_model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "sGSjvnn3Rb33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## testing the accuracy before adversarial training"
      ],
      "metadata": {
        "id": "Sh8bXMYQ8sSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n_concepts = 8\n",
        "model = Sequential(8)\n",
        "model.load_state_dict(torch.load(\"sequential3.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "6Acseei2T9bo",
        "outputId": "eeb9e5a1-c5ed-4874-eb32-778c2a5f8d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9f0defcdcf12>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_concepts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sequential3.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sequential3.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd_linf_targ(model, data_loader, epsilon, alpha, num_iter, y_targ, example):\n",
        "    \"\"\"\n",
        "      Training on the whole test set\n",
        "    \"\"\"\n",
        "    delta = torch.zeros_like(example, requires_grad=True)\n",
        "    for t in range(num_iter):\n",
        "      print(f\"Running iteration {t}\")\n",
        "      for X, y, concepts in data_loader:\n",
        "        X, y, concepts = images.to(device), labels.to(device), concepts.to(device)\n",
        "        yp = model(X + delta)\n",
        "        loss = 2*yp[:, y_targ].sum() - yp.sum()\n",
        "        loss.backward()\n",
        "\n",
        "        delta = delta + alpha * delta.grad.detach().sign()\n",
        "        delta = delta.clamp(-epsilon, epsilon).detach().requires_grad_(True)\n",
        "\n",
        "        # Clear gradients after updating delta\n",
        "        if delta.grad is not None:\n",
        "            delta.grad.zero_()\n",
        "    return delta.detach()\n",
        "\n",
        "\n",
        "for images, labels, concepts in test_loader:\n",
        "    images, labels, concepts = images.to(device), labels.to(device), concepts.to(device)\n",
        "    break\n",
        "delta = pgd_linf_targ(model, test_loader, epsilon=0.4, alpha=1e-2, num_iter=20, y_targ=2, example=images)\n",
        "yp = model(images + delta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CW14ukG9ApF",
        "outputId": "d0252506-19e4-4983-d941-fdb5a73b2cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running iteration 0\n",
            "Running iteration 1\n",
            "Running iteration 2\n",
            "Running iteration 3\n",
            "Running iteration 4\n",
            "Running iteration 5\n",
            "Running iteration 6\n",
            "Running iteration 7\n",
            "Running iteration 8\n",
            "Running iteration 9\n",
            "Running iteration 10\n",
            "Running iteration 11\n",
            "Running iteration 12\n",
            "Running iteration 13\n",
            "Running iteration 14\n",
            "Running iteration 15\n",
            "Running iteration 16\n",
            "Running iteration 17\n",
            "Running iteration 18\n",
            "Running iteration 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.calc_acc_prediction(test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeJ93tiE81Se",
        "outputId": "005a341a-329b-4180-dcd5-f9843a7f559c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9892515923566879"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.calc_acc_prediction(test_loader, delta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f4zCmSb9fGM",
        "outputId": "f7ac6e22-7185-49e0-df86-31f0c854174e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2428343949044586"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_adversarial(loader, model, attack, opt=None, **kwargs):\n",
        "    \"\"\"Adversarial training/evaluation epoch over the dataset\"\"\"\n",
        "    total_loss, total_err = 0.,0.\n",
        "    for X,y,_ in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        delta = attack(model, X, y)\n",
        "        yp = model(X+delta)\n",
        "        loss = nn.CrossEntropyLoss()(yp,y)\n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        total_err += (yp.max(dim=1)[1] != y.argmax(dim=1)).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n"
      ],
      "metadata": {
        "id": "0Py7WfUbS25N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd_linf_targ(model, X,y, epsilon=0.4, alpha=1e-2, num_iter=20, y_targ=2):\n",
        "    \"\"\"\n",
        "      Training on the whole test set\n",
        "    \"\"\"\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    delta = torch.zeros_like(X, requires_grad=True)\n",
        "    for t in range(num_iter):\n",
        "\n",
        "      yp = model(X + delta)\n",
        "      loss = 2*yp[:, y_targ].sum() - yp.sum()\n",
        "      loss.backward()\n",
        "\n",
        "      delta = delta + alpha * delta.grad.detach().sign()\n",
        "      delta = delta.clamp(-epsilon, epsilon).detach().requires_grad_(True)\n",
        "\n",
        "      # Clear gradients after updating delta\n",
        "      if delta.grad is not None:\n",
        "          delta.grad.zero_()\n",
        "    return delta.detach()\n"
      ],
      "metadata": {
        "id": "mfK2d8aBReDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
        "for t in range(10):\n",
        "    print(f\"Running iteration {t}\")\n",
        "    train_err, train_loss = epoch_adversarial(train_loader, model, pgd_linf_targ, opt)\n",
        "    adv_err, adv_loss = epoch_adversarial(test_loader, model, pgd_linf_targ)\n",
        "    if t == 4:\n",
        "        for param_group in opt.param_groups:\n",
        "            param_group[\"lr\"] = 1e-5\n",
        "    print(*(\"{:.6f}\".format(i) for i in (train_err, adv_err)), sep=\"\\t\")\n",
        "torch.save(model.state_dict(), \"model_robust.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9u0fkheTVHP",
        "outputId": "12569170-f1e6-46d3-d8b6-f53810757139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running iteration 0\n",
            "0.018733\t0.019000\n",
            "Running iteration 1\n",
            "0.016917\t0.018000\n",
            "Running iteration 2\n",
            "0.014700\t0.014900\n",
            "Running iteration 3\n",
            "0.013517\t0.015000\n",
            "Running iteration 4\n",
            "0.012850\t0.016500\n",
            "Running iteration 5\n",
            "0.010500\t0.014400\n",
            "Running iteration 6\n",
            "0.010117\t0.014000\n",
            "Running iteration 7\n",
            "0.009667\t0.014700\n",
            "Running iteration 8\n",
            "0.009033\t0.014500\n",
            "Running iteration 9\n",
            "0.009550\t0.014000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.calc_acc_prediction(test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn744SRwVvrI",
        "outputId": "c9a31c64-eee7-48fd-aca2-887c03d322bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9299363057324841"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.calc_acc_prediction(test_loader, delta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnRYOB8uAohL",
        "outputId": "123a10a8-72f9-4fd2-b18a-53986c78ad83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4476512738853503"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adversarially training the joint model"
      ],
      "metadata": {
        "id": "0QpVK0zpAuIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Joint(nn.Module):\n",
        "    def __init__(self, n_concepts):\n",
        "        super(Joint, self).__init__()\n",
        "        self.g_model = g(n_concepts).to(device)\n",
        "        self.f_model = f(10+n_concepts*2).to(device)\n",
        "\n",
        "        self.name = 'joint'\n",
        "\n",
        "    def forward(self, x):\n",
        "        non_overlapping, overlapping = self.g_model(x)\n",
        "        overlapping_concat = torch.cat([non_overlapping, overlapping], dim=1)\n",
        "        y_pred = self.f_model(overlapping_concat)\n",
        "        return y_pred, non_overlapping, overlapping\n",
        "\n",
        "\n",
        "    def loss_overlapping(self, overlapping, y_true):\n",
        "        total_loss = 0\n",
        "        concept_idx = 0\n",
        "        # print(overlapping.shape)\n",
        "        for i in range(0, overlapping.shape[1], 2):\n",
        "            loss = nn.CrossEntropyLoss()(overlapping[:, i:i+2], y_true[:, concept_idx].long())\n",
        "            concept_idx += 1\n",
        "            total_loss += loss\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m-hkD7cNA521"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the accuracy of the model before the adversarial training"
      ],
      "metadata": {
        "id": "zeqDSZc8AxY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joint_model = Joint(8)\n",
        "joint_model.load_state_dict(torch.load(r\"/content/joint_model2.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI0gle7-BIsv",
        "outputId": "23a0f951-88ce-48f0-bae7-c38c3f38f9f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_joint(model, test_loader):\n",
        "    model.eval()\n",
        "    accuracies = []\n",
        "    for images, labels, concepts in test_loader:\n",
        "        images, labels, concepts = images.to(device), labels.to(device), concepts.to(device)\n",
        "        y_pred, _, _ = model(images)\n",
        "        acc = (y_pred.argmax(dim=1) == labels.argmax(dim=1)).float().mean().item()\n",
        "        accuracies.append(acc)\n",
        "    return sum(accuracies)/len(accuracies)\n",
        "test_joint(joint_model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_UUcigRAtvQ",
        "outputId": "67fb0395-2b92-40ea-d30c-6f8cfb9abed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9892515923566879"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd_linf_targ(model, data_loader, epsilon, alpha, num_iter, y_targ, example):\n",
        "    \"\"\"\n",
        "      Training on the whole test set\n",
        "    \"\"\"\n",
        "    delta = torch.zeros_like(example, requires_grad=True)\n",
        "    for t in range(num_iter):\n",
        "      print(f\"Running iteration {t}\")\n",
        "      for X, y, concepts in data_loader:\n",
        "        X, y, concepts = images.to(device), labels.to(device), concepts.to(device)\n",
        "        yp, _, _ = model(X + delta)\n",
        "        loss = 2*yp[:, y_targ].sum() - yp.sum()\n",
        "        loss.backward()\n",
        "\n",
        "        delta = delta + alpha * delta.grad.detach().sign()\n",
        "        delta = delta.clamp(-epsilon, epsilon).detach().requires_grad_(True)\n",
        "\n",
        "        # Clear gradients after updating delta\n",
        "        if delta.grad is not None:\n",
        "            delta.grad.zero_()\n",
        "    return delta.detach()\n",
        "\n",
        "\n",
        "for images, labels, concepts in test_loader:\n",
        "    images, labels, concepts = images.to(device), labels.to(device), concepts.to(device)\n",
        "    break\n",
        "delta = pgd_linf_targ(joint_model, test_loader, epsilon=0.4, alpha=1e-2, num_iter=20, y_targ=2, example=images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cxQT9R_BH-8",
        "outputId": "b8ada782-a16d-4b69-b663-4ca6d3cc3279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running iteration 0\n",
            "Running iteration 1\n",
            "Running iteration 2\n",
            "Running iteration 3\n",
            "Running iteration 4\n",
            "Running iteration 5\n",
            "Running iteration 6\n",
            "Running iteration 7\n",
            "Running iteration 8\n",
            "Running iteration 9\n",
            "Running iteration 10\n",
            "Running iteration 11\n",
            "Running iteration 12\n",
            "Running iteration 13\n",
            "Running iteration 14\n",
            "Running iteration 15\n",
            "Running iteration 16\n",
            "Running iteration 17\n",
            "Running iteration 18\n",
            "Running iteration 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_joint_addv(model, test_loader, delta):\n",
        "    model.eval()\n",
        "    accuracies = []\n",
        "    for images, labels, concepts in test_loader:\n",
        "        images, labels, concepts = images.to(device), labels.to(device), concepts.to(device)\n",
        "        y_pred, _, _ = model(images + delta[:images.shape[0]])\n",
        "        acc = (y_pred.argmax(dim=1) == labels.argmax(dim=1)).float().mean().item()\n",
        "        accuracies.append(acc)\n",
        "    return sum(accuracies)/len(accuracies)\n",
        "test_joint_addv(joint_model, test_loader, delta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xwkEYKlBuSD",
        "outputId": "d1884bd9-9e35-4380-a92c-06d0de711266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16660031847133758"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adversarially training the joint model"
      ],
      "metadata": {
        "id": "WDhC-eH9CJ2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd_linf_targ(model, X,y, epsilon=0.4, alpha=1e-2, num_iter=20, y_targ=2):\n",
        "    \"\"\"\n",
        "      Training on the whole test set\n",
        "    \"\"\"\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    delta = torch.zeros_like(X, requires_grad=True)\n",
        "    for t in range(num_iter):\n",
        "      yp, _, _ = model(X + delta)\n",
        "      loss = 2*yp[:, y_targ].sum() - yp.sum()\n",
        "      loss.backward()\n",
        "\n",
        "      delta = delta + alpha * delta.grad.detach().sign()\n",
        "      delta = delta.clamp(-epsilon, epsilon).detach().requires_grad_(True)\n",
        "\n",
        "      # Clear gradients after updating delta\n",
        "      if delta.grad is not None:\n",
        "          delta.grad.zero_()\n",
        "    return delta.detach()\n"
      ],
      "metadata": {
        "id": "TwV4yc1UCgqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_adversarial(loader, model, attack, opt=None, **kwargs):\n",
        "    \"\"\"Adversarial training/evaluation epoch over the dataset\"\"\"\n",
        "    total_loss, total_err = 0.,0.\n",
        "    for X,y,_ in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        delta = attack(model, X, y)\n",
        "        yp, _, _ = model(X+delta)\n",
        "        loss = nn.CrossEntropyLoss()(yp,y)\n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        total_err += (yp.max(dim=1)[1] != y.argmax(dim=1)).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n"
      ],
      "metadata": {
        "id": "znpePP0jCt7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optim.Adam(joint_model.parameters(), lr=1e-4)\n",
        "for t in range(10):\n",
        "    print(f\"Running iteration {t}\")\n",
        "    train_err, train_loss = epoch_adversarial(train_loader, joint_model, pgd_linf_targ, opt)\n",
        "    adv_err, adv_loss = epoch_adversarial(test_loader, joint_model, pgd_linf_targ)\n",
        "    if t == 4:\n",
        "        for param_group in opt.param_groups:\n",
        "            param_group[\"lr\"] = 1e-5\n",
        "    print(*(\"{:.6f}\".format(i) for i in (train_err, adv_err)), sep=\"\\t\")\n",
        "torch.save(joint_model.state_dict(), \"joint_robust.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9pp_NQsCDux",
        "outputId": "f710db65-f1d7-4401-ae2b-a14b1512aea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running iteration 0\n",
            "0.018900\t0.018700\n",
            "Running iteration 1\n",
            "0.014833\t0.016600\n",
            "Running iteration 2\n",
            "0.013683\t0.015400\n",
            "Running iteration 3\n",
            "0.012183\t0.014300\n",
            "Running iteration 4\n",
            "0.011600\t0.015600\n",
            "Running iteration 5\n",
            "0.008800\t0.013400\n",
            "Running iteration 6\n",
            "0.008200\t0.013000\n",
            "Running iteration 7\n",
            "0.007950\t0.012500\n",
            "Running iteration 8\n",
            "0.007567\t0.012700\n",
            "Running iteration 9\n",
            "0.007733\t0.012300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_joint_addv(joint_model, test_loader, delta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIP_KqadC47X",
        "outputId": "6ce6dd3b-b0ba-45c9-db71-dbd361b772c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5200039808917197"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_joint(joint_model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzYEQIw7F1yZ",
        "outputId": "1cda7785-b6d1-4978-bd48-40d5df9d4e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.856687898089172"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adversarially training CNN model"
      ],
      "metadata": {
        "id": "Ok7VXinoF8Gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(CNN, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "      self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
        "      self.fc1 = nn.Linear(800, 128)\n",
        "      self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "      self.name = 'CNN'\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "xflX-Tf2F-wr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = CNN().to(device)\n",
        "cnn_model.load_state_dict(torch.load('cnn1.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M6sgLYXGBAc",
        "outputId": "f5c1c463-320d-4fcd-b830-daa5f69bb77b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_cnn(model, test_loader):\n",
        "  model.eval()\n",
        "  accuracies = []\n",
        "  for images, labels, _ in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    y_pred = model(images).argmax(dim=1)\n",
        "    acc = (y_pred == labels.argmax(dim=1)).float().mean().item()\n",
        "    accuracies.append(acc)\n",
        "  return sum(accuracies)/len(accuracies)\n",
        "test_cnn(cnn_model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtGOTCktGKrA",
        "outputId": "0604a34e-255d-4954-a76d-c00e3563ebd4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9886544585987261"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd_linf_targ(model, data_loader, epsilon, alpha, num_iter, y_targ, example):\n",
        "    delta = torch.zeros_like(example, requires_grad=True)\n",
        "    for t in range(num_iter):\n",
        "      print(f\"Running iteration {t}\")\n",
        "      for X, y, concepts in data_loader:\n",
        "        X, y, concepts = images.to(device), labels.to(device), concepts.to(device)\n",
        "        yp = model(X + delta)\n",
        "        loss = 2*yp[:, y_targ].sum() - yp.sum()\n",
        "        loss.backward()\n",
        "\n",
        "        delta = delta + alpha * delta.grad.detach().sign()\n",
        "        delta = delta.clamp(-epsilon, epsilon).detach().requires_grad_(True)\n",
        "\n",
        "        # Clear gradients after updating delta\n",
        "        if delta.grad is not None:\n",
        "            delta.grad.zero_()\n",
        "    return delta.detach()\n",
        "\n",
        "\n",
        "for images, labels, concepts in test_loader:\n",
        "    images, labels, concepts = images.to(device), labels.to(device), concepts.to(device)\n",
        "    break\n",
        "delta = pgd_linf_targ(cnn_model, test_loader, epsilon=0.4, alpha=1e-2, num_iter=20, y_targ=2, example=images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjdPKWIiGZRK",
        "outputId": "ab95c776-a31e-4358-9cbb-2d4a8b3cdc6b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running iteration 0\n",
            "Running iteration 1\n",
            "Running iteration 2\n",
            "Running iteration 3\n",
            "Running iteration 4\n",
            "Running iteration 5\n",
            "Running iteration 6\n",
            "Running iteration 7\n",
            "Running iteration 8\n",
            "Running iteration 9\n",
            "Running iteration 10\n",
            "Running iteration 11\n",
            "Running iteration 12\n",
            "Running iteration 13\n",
            "Running iteration 14\n",
            "Running iteration 15\n",
            "Running iteration 16\n",
            "Running iteration 17\n",
            "Running iteration 18\n",
            "Running iteration 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_cnn_addv(model, test_loader, delta):\n",
        "    model.eval()\n",
        "    accuracies = []\n",
        "    for images, labels, concepts in test_loader:\n",
        "        images, labels, concepts = images.to(device), labels.to(device), concepts.to(device)\n",
        "        y_pred = model(images + delta[:images.shape[0]])\n",
        "        acc = (y_pred.argmax(dim=1) == labels.argmax(dim=1)).float().mean().item()\n",
        "        accuracies.append(acc)\n",
        "    return sum(accuracies)/len(accuracies)\n",
        "test_cnn_addv(cnn_model, test_loader, delta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv403LjlGc-I",
        "outputId": "75a868f2-9885-42af-f5d7-94f31b4a7c93"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11624203821656051"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_adversarial(loader, model, attack, opt=None, **kwargs):\n",
        "    \"\"\"Adversarial training/evaluation epoch over the dataset\"\"\"\n",
        "    total_loss, total_err = 0.,0.\n",
        "    for X,y,_ in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        delta = attack(model, X, y)\n",
        "        yp = model(X+delta)\n",
        "        loss = nn.CrossEntropyLoss()(yp,y)\n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        total_err += (yp.max(dim=1)[1] != y.argmax(dim=1)).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n"
      ],
      "metadata": {
        "id": "QSTA8PcOJTUc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd_linf_targ(model, X,y, epsilon=0.4, alpha=1e-2, num_iter=20, y_targ=2):\n",
        "    \"\"\"\n",
        "      Training on the whole test set\n",
        "    \"\"\"\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    delta = torch.zeros_like(X, requires_grad=True)\n",
        "    for t in range(num_iter):\n",
        "\n",
        "      yp = model(X + delta)\n",
        "      loss = 2*yp[:, y_targ].sum() - yp.sum()\n",
        "      loss.backward()\n",
        "\n",
        "      delta = delta + alpha * delta.grad.detach().sign()\n",
        "      delta = delta.clamp(-epsilon, epsilon).detach().requires_grad_(True)\n",
        "\n",
        "      # Clear gradients after updating delta\n",
        "      if delta.grad is not None:\n",
        "          delta.grad.zero_()\n",
        "    return delta.detach()\n"
      ],
      "metadata": {
        "id": "a4-CpEUeJTvB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optim.Adam(cnn_model.parameters(), lr=1e-4)\n",
        "for t in range(10):\n",
        "    print(f\"Running iteration {t}\")\n",
        "    train_err, train_loss = epoch_adversarial(train_loader, cnn_model, pgd_linf_targ, opt)\n",
        "    adv_err, adv_loss = epoch_adversarial(test_loader, cnn_model, pgd_linf_targ)\n",
        "    if t == 4:\n",
        "        for param_group in opt.param_groups:\n",
        "            param_group[\"lr\"] = 1e-5\n",
        "    print(*(\"{:.6f}\".format(i) for i in (train_err, adv_err)), sep=\"\\t\")\n",
        "torch.save(cnn_model.state_dict(), \"cnn_robust.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K2RHy4JJZd1",
        "outputId": "ccb2b742-b3b8-4d2a-d48d-163ba0ed869b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running iteration 0\n",
            "0.022183\t0.017000\n",
            "Running iteration 1\n",
            "0.012850\t0.017700\n",
            "Running iteration 2\n",
            "0.011750\t0.015200\n",
            "Running iteration 3\n",
            "0.010233\t0.015700\n",
            "Running iteration 4\n",
            "0.009867\t0.013200\n",
            "Running iteration 5\n",
            "0.007383\t0.013200\n",
            "Running iteration 6\n",
            "0.007283\t0.013200\n",
            "Running iteration 7\n",
            "0.006950\t0.013400\n",
            "Running iteration 8\n",
            "0.006883\t0.012800\n",
            "Running iteration 9\n",
            "0.006783\t0.013300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_cnn(cnn_model, test_loader)"
      ],
      "metadata": {
        "id": "Khkd3ga6M8hN",
        "outputId": "a54185bf-eb0c-4d5e-96d6-b445de9d9b1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8883359872611465"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_cnn_addv(cnn_model, test_loader, delta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6Erm3tlJlal",
        "outputId": "c0615133-83ce-42c3-a2ea-bd731d663306"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6283837579617835"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NuhL6tjmmmnV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}